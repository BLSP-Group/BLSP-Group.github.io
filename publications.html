<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="Publications">
    <meta name="author" content="WeiQM">
    <link rel="icon" href="images/logo/RMX_16.ico">
    <title>REMEX - Publications</title>
    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="style/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <!-- Custom styles for this template -->
    <link href="style/jquery.bxslider.css" rel="stylesheet">
    <link href="style/style.css" rel="stylesheet">

  </head>
  <body>
    <!-- Navigation -->
    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          </button>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li><a href="index.html">Home</a></li>
            <li><a href="people.html">People</a></li>
            <li><a href="research.html">Research</a></li>
            <li class="active"><a href="publications.html">Publications</a></li>
            <li><a href="downloads.html">Downloads</a></li>
            <li><a href="contact.html">Contact Us</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <li class="active"><a href="publications.html">English</a></li>
            <li><a href="html/cn/publications.html">中文</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <li><a href="index.html"><img src="images/logo/logo_w.png" alt="Logo" width="80px"/></a></li>
          </ul>
        </div>
      </div>
    </nav>

    <div class="container">
    <header>
      <!--
      <a href="index.html"><img src="images/logo.png"  width="256px"></a>
      -->
    </header>

    <!--
    <section class="main-slider">
      <ul class="bxslider">
        <li><div class="slider-item"><img src="images/logo/logo_c.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_m.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_y.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_k.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_r.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_g.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_b.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
      </ul>
    </section>
    -->

    <section>
      <div class="row">
      <div class="col-md-12">
      <article class="content-block">
      <div class="block-body">
      <div class="block-text">


        <!-- -------------------------------------------- -->
        <!-- -------------------------------------------- -->
        <h3>2018</h3>
        <table><tbody>
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_ma_jbhi_2016.jpg" alt="Result" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Generating Region Proposals for Histopathological Whole Slide Image Retrieval</b> <a href="http://www.sciencedirect.com/science/article/pii/S0169260717312154" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                    Yibing Ma, Zhiguo Jiang, Haopeng Zhang, Fengying Xie, Yushan Zheng, Huaqiang Shi, Yu Zhao and Jun Shi
                </i></font>
                <br>
                  CMPB, 2018
                <br>
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('maCMBP2018Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('maCMBP2018Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="maCMBP2018Abs" class="abstract" style="display: none;">
                  <b>Background and objective</b>
                  Content-based image retrieval is an effective method for histopathological image analysis. However, given a database of huge whole slide images (WSIs), acquiring appropriate region-of-interests (ROIs) for training is significant and difficult. Moreover, histopathological images can only be annotated by pathologists, resulting in the lack of labeling information. Therefore, it is an important and challenging task to generate ROIs from WSI and retrieve image with few labels.
                  <b>Methods</b>
                  This paper presents a novel unsupervised region proposing method for histopathological WSI based on Selective Search. Specifically, the WSI is over-segmented into regions which are hierarchically merged until the WSI becomes a single region. Nucleus-oriented similarity measures for region mergence and Nucleus–Cytoplasm color space for histopathological image are specially defined to generate accurate region proposals. Additionally, we propose a new semi-supervised hashing method for image retrieval. The semantic features of images are extracted with Latent Dirichlet Allocation and transformed into binary hashing codes with Supervised Hashing.
                  <b>Results</b>
                  The methods are tested on a large-scale multi-class database of breast histopathological WSIs. The results demonstrate that for one WSI, our region proposing method can generate 7.3 thousand contoured regions which fit well with 95.8% of the ROIs annotated by pathologists. The proposed hashing method can retrieve a query image among 136 thousand images in 0.29 s and reach precision of 91% with only 10% of images labeled.
                  <b>Conclusions</b>
                  The unsupervised region proposing method can generate regions as predictions of lesions in histopathological WSI. The region proposals can also serve as the training samples to train machine-learning models for image retrieval. The proposed hashing method can achieve fast and precise image retrieval with small amount of labels. Furthermore, the proposed methods can be potentially applied in online computer-aided-diagnosis systems.
                </p>
              <pre xml:space="preserve" id="maCMBP2018Bib" class="bibtex" style="display: none;">
@article{maCMPB2018,
  title   = {Generating region proposals for histopathological whole slide image retrieval},
  author  = {Yibing Ma and Zhiguo Jiang and Haopeng Zhang and Fengying Xie 
            and Yushan Zheng and Huaqiang Shi and Yu Zhao and Jun Shi},
  journal = {Computer Methods and Programs in Biomedicine},
  volume  = {159},
  pages   = {1 - 10},
  year    = {2018},
  issn    = {0169-2607},
  url     = {http://www.sciencedirect.com/science/article/pii/S0169260717312154},
}      
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('maCMBP2018Abs');
                hideblock('maCMBP2018Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_zheng_tmi_2018.jpg" alt="Flowchart" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Histopathological Whole Slide Image Analysis Using Context-based CBIR</b> <a href="http://ieeexplore.ieee.org/document/8265156/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yushan Zheng, Zhiguo Jiang, Haopeng Zhang, Fengying Xie, Yibing Ma, Huaqiang Shi and Yu Zhao
                </i></font>
                <br>
                 TMI, 2018
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="source/pdf/article_zheng_tmi_2018.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhengTMI2018Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhengTMI2018Bib')">BibTeX</a> &nbsp;
                <i class="fa fa-link"></i> <a href="source/pdf/article_zheng_tmi_2018_sup.pdf" target="_blank">Supplementary</a> &nbsp;
              </p>
              <p id="zhengTMI2018Abs" class="abstract" style="display: none;">
                Histopathological image classification (HIC) and content-based histopathological image retrieval (CBHIR) are two promising applications for histopathological whole slide image (WSI) analysis. HIC can efficiently predict the type of lesion involved in a histopathological image. In general, HIC can aid pathologists in locating high-risk cancer regions from a WSI by providing a cancerous probability map for the WSI. In contrast, CBHIR was developed to allow searches for regions with similar content for a region of interest (ROI) from a database consisting of historical cases. Sets of cases with similar content are accessible to pathologists, which can provide more valuable references for diagnosis. A drawback of the recent CBHIR framework is that a query ROI needs to be manually selected from a WSI. An automatic CBHIR approach for a WSI-wise analysis needs to be developed. In this paper, we propose a novel aided-diagnosis framework of breast cancer using whole slide images, which shares the advantages of both HIC and CBHIR. In our framework, CBHIR is automatically processed throughout the WSI, based on which a probability map regarding the malignancy of breast tumors is calculated. Through the probability map, the malignant regions in WSIs can be easily recognized. Furthermore, the retrieval results corresponding to each sub-region of the WSIs are recorded during the automatic analysis and are available to pathologists during their diagnosis. Our method was validated on fully annotated WSI datasets of breast tumors. The experimental results certify the effectiveness of the proposed method.
              </p>
              <pre xml:space="preserve" id="zhengTMI2018Bib" class="bibtex" style="display: none;">
@article{zhengTMI18,
  author  = {Yushan Zheng and Zhiguo Jiang and Haopeng Zhang and Fengying Xie
             and Yibing Ma and Huaqiang Shi and Yu Zhao},
  title   = {Histopathological Whole Slide Image Analysis Using Context-based CBIR},
  journal = {IEEE Transactions on Medical Imaging},
  doi     = {10.1109/TMI.2018.2796130},
  year    = {Epub 2018 January 23}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhengTMI2018Abs');
                hideblock('zhengTMI2018Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_wei_sensors_2018.jpg" alt="Results of article_wei_sensors_18" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Robust Spacecraft Component Detection in Point Clouds</b> <a href="http://www.mdpi.com/1424-8220/18/4/933" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  <a href="https://weiquanmao.github.io" target="_blank">Quanmao Wei</a>, Zhiguo Jiang and Haopeng Zhang
                </i></font>
                <br>
                Sensors, 2018
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="http://www.mdpi.com/1424-8220/18/4/933/pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('weiSensors18Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('weiSensors18Bib')">BibTeX</a> &nbsp;
                <i class="fa fa-link"></i> <a href="http://www.mdpi.com/1424-8220/18/4/933/s1" target="_blank">Supplementary</a> &nbsp;
                <i class="fa fa-code"></i> <a href="https://github.com/weiquanmao/PCF" target="_blank">Code</a> &nbsp
              </p>
              <p id="weiSensors18Abs" class="abstract" style="display: none;">
                Automatic component detection of spacecraft can assist in on-orbit operation and space situational awareness. Spacecraft are generally composed of solar panels and cuboidal or cylindrical modules. These components can be simply represented by geometric primitives like plane, cuboid and cylinder. Based on this prior, we propose a robust automatic detection scheme to automatically detect such basic components of spacecraft in three-dimensional (3D) point clouds. In the proposed scheme, cylinders are first detected in the iteration of the energy-based geometric model fitting and cylinder parameter estimation. Then, planes are detected by Hough transform and further described as bounded patches with their minimum bounding rectangles. Finally, the cuboids are detected with pair-wise geometry relations from the detected patches. After successive detection of cylinders, planar patches and cuboids, a mid-level geometry representation of the spacecraft can be delivered. We tested the proposed component detection scheme on spacecraft 3D point clouds synthesized by computer-aided design (CAD) models and those recovered by image-based reconstruction, respectively. Experimental results illustrate that the proposed scheme can detect the basic geometric components effectively and has fine robustness against noise and point distribution density.
              </p>
              <pre xml:space="preserve" id="weiSensors18Bib" class="bibtex" style="display: none;">
@article{weiSensors18,
  author  = {Quanmao Wei and Zhiguo Jiang and Haopeng Zhang},
  title   = {Robust Spacecraft Component Detection in Point Clouds},
  journal = {Sensors},
  volume  = {18},
  year    = {2018},
  number  = {4},
  article number = {933},
  url     = {http://www.mdpi.com/1424-8220/18/4/933},
  issn    = {1424—8220},
  doi     = {10.3390/s18040933}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('weiSensors18Abs');
                hideblock('weiSensors18Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_zhang_taes_2018.jpg" alt="Results of article_zhang_taes_18" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Vision-based Pose Estimation for Textureless Space Objects by Contour Points Matching</b> <a href="http://ieeexplore.ieee.org/document/8315479/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Xin Zhang, Zhiguo Jiang, Haopeng Zhang and <a href="https://weiquanmao.github.io" target="_blank">Quanmao Wei</a>
                </i></font>
                <br>
                TAES, 2018
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8315479" target="_blank">Preprint</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhangTAES18Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhangTAES18Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhangTAES18Abs" class="abstract" style="display: none;">
                This paper presents a novel vision-based method to solve the 6-degree-of-freedom pose estimation problem of textureless space objects from a single monocular image. Our approach follows a coarse-to-fine procedure, utilizing only shape and contour information of the input image. To achieve invariance to initialization, we select a series of projection images which are similar to the input image and establish many-to-one 2D-3D correspondences by contour feature matching. Intensive attention is focused on outlier rejection and we introduce an innovative strategy to fully utilize geometric matching information to guide pose calculation. Experiments based on simulated images are carried out, and the results manifest that pose estimation error of our approach is about 1% even in situations with heavy outlier correspondences.
              </p>
              <pre xml:space="preserve" id="zhangTAES18Bib" class="bibtex" style="display: none;">
@article{zhangTAES18,
  author  = {Xin Zhang and Zhiguo Jiang and Haopeng Zhang and Quanmao Wei},
  journal = {IEEE Transactions on Aerospace and Electronic Systems},
  title   = {Vision-based Pose Estimation for Textureless Space Objects
             by Contour Points Matching},
  year    = {2018},
  month   = {},
  volume  = {PP},
  number  = {99},
  pages   = {1—-1},
  issn    = {0018-9251},
  doi     = {10.1109/TAES.2018.2815879}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhangTAES18Abs');
                hideblock('zhangTAES18Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
        </tbody></table>

        <hr />
        <!-- -------------------------------------------- -->
        <!-- -------------------------------------------- -->
        <h3>2017</h3>
        <table><tbody>
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_zheng_jbhi_2017.jpg" alt="Flowchart" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Size-scalable Content-based Histopathological Image Retrieval from Ratabase that Ronsists of WSIs</b> <a href="http://ieeexplore.ieee.org/document/7967806/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yushan Zheng, Zhiguo Jiang, Haopeng Zhang, Fengying Xie, Yibing Ma, Huaqiang Shi and Yu Zhao
                </i></font>
                <br>
                JBHI, 2017
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="source/pdf/article_zheng_jbhi_2017.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhengJBHI2017Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhengJBHI2017Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhengJBHI2017Abs" class="abstract" style="display: none;">
                Content-based image retrieval (CBIR) has been widely researched for histopathological images. It is challenging to retrieve contently similar regions from histopathological whole slide images (WSIs) for regions of interest (ROIs) in different size. In this paper, we propose a novel CBIR framework for database that consists of WSIs and size-scalable query ROIs. Each WSI in the database is encoded into a matrix of binary codes. When retrieving, a group of region proposals that have similar size with the query ROI are firstly located in the database through an efficient table-lookup approach. Then, these regions are ranked by a designed multi-binary-code-based similarity measurement. Finally, the top relevant regions and their locations in the WSIs as well as the corresponding diagnostic information are returned to assist pathologists. The effectiveness of the proposed framework is evaluated on a fine-annotated WSI database of epithelial breast tumors. The experimental results have proved that the proposed framework is effective for retrieval from database that consists of WSIs. Specifically, for query ROIs of 4096$\times$4096 pixels, the retrieval precision of the top 20 return has reached 96\% and the retrieval time is less than 1.5 second.
              </p>
              <pre xml:space="preserve" id="zhengJBHI2017Bib" class="bibtex" style="display: none;">
@article{zhengJBHI17,
  author  = {Yushan Zheng and Zhiguo Jiang Haopeng Zhang and Fengying Xie
             and Yibing Ma and Huaqiang Shi and Yu Zhao},
  title   = {Size-scalable Content-based Histopathological Image Retrieval
             from Database that Consists of WSIs},
  journal = {IEEE journal of biomedical and health informatics},
  doi     = {10.1109/jbhi.2017.2723014},
  year    = {2017}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhengJBHI2017Abs');
                hideblock('zhengJBHI2017Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_zheng_pr_2017.jpg" alt="Flowchart_of_N_CNN" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Feature Extraction from Histopathological Images Based on Nucleus-guided Convolutional Neural Network for Breast Lesion Classification</b> <a href="https://www.sciencedirect.com/science/article/pii/S0031320317302005?via%3Dihub" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yushan Zheng, Zhiguo Jiang, Fengying Xie, Haopeng Zhang, Yibing Ma, Huaqiang Shi and Yu Zhao
                </i></font>
                <br>
                PR, 2017
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="source/pdf/article_zheng_pr_2017.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhengPR2017Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhengPR2017Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhengPR2017Abs" class="abstract" style="display: none;">
                Feature extraction is a crucial and challenging aspect in the computer-aided diagnosis of breast cancer with histopathological images. In recent years, many machine learning methods have been introduced to extract features from histopathological images. In this study, a novel nucleus-guided feature extraction framework based on convolutional neural network is proposed for histopathological images. The nuclei are first detected from images, and then used to train a designed convolutional neural network with three hierarchy structures. Through the trained network, image-level features including the pattern and spatial distribution of the nuclei are extracted. The proposed features are evaluated through the classification experiment on a histopathological image database of breast lesions. The experimental results show that the extracted features effectively represent histopathological images, and the proposed framework achieves a better classification performance for breast lesions than the compared state-of-the-art methods.
              </p>
              <pre xml:space="preserve" id="zhengPR2017Bib" class="bibtex" style="display: none;">
@article{zhengPR17,
  author  = {Yushan Zheng and Zhiguo Jiang and Fengying Xie and Haopeng Zhang
             and Yibing Ma and Huaqiang Shi and Yu Zhao},
  title   = {Feature Extraction from Histopathological Images Based on Nucleus-guided
             Convolutional Neural Network for Breast Lesion Classification},
  journal = {Pattern Recognition},
  year    = {2017},
  volume  = {71},
  pages   = {14—-25},
  issn    = {0031-3203},
  doi     = {10.1016/j.patcog.2017.05.010}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhengPR2017Abs');
                hideblock('zhengPR2017Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_zhang_sensors_2017.jpg" alt="Results of article_zhang_sensors_17" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>3D Reconstruction of Space Objects from Multi-Views by A Visible Sensor</b> <a href="http://www.mdpi.com/1424-8220/17/7/1689" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Haopeng Zhang, <a href="https://weiquanmao.github.io" target="_blank">Quanmao Wei</a> and Zhiguo Jiang
                </i></font>
                <br>
                Sensors, 2017
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="http://www.mdpi.com/1424-8220/17/7/1689/pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhangSensors17Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhangSensors17Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhangSensors17Abs" class="abstract" style="display: none;">
                In this paper, a novel 3D reconstruction framework is proposed to recover the 3D structural model of a space object from its multi-view images captured by a visible sensor. Given an image sequence, this framework first estimates the relative camera poses and recovers the depths of the surface points by the structure from motion (SFM) method, then the patch-based multi-view stereo (PMVS) algorithm is utilized to generate a dense 3D point cloud. To resolve the wrong matches arising from the symmetric structure and repeated textures of space objects, a new strategy is introduced, in which images are added to SFM in imaging order. Meanwhile, a refining process exploiting the structural prior knowledge that most sub-components of artificial space objects are composed of basic geometric shapes is proposed and applied to the recovered point cloud. The proposed reconstruction framework is tested on both simulated image datasets and real image datasets. Experimental results illustrate that the recovered point cloud models of space objects are accurate and have a complete coverage of the surface. Moreover, outliers and points with severe noise are effectively filtered out by the refinement, resulting in an distinct improvement of the structure and visualization of the recovered points.
              </p>
              <pre xml:space="preserve" id="zhangSensors17Bib" class="bibtex" style="display: none;">
@article{zhangSensors17,
  author  = {Haopeng Zhang and Quanmao Wei and Zhiguo Jiang},
  title   = {3D Reconstruction of Space Objects from Multi-Views by A Visible Sensor},
  journal = {Sensors},
  volume  = {17},
  year    = {2017},
  number  = {7},
  article number = {1689},
  url     = {http://www.mdpi.com/1424-8220/17/7/1689},
  issn    = {1424-8220},
  doi     = {10.3390/s17071689}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhangSensors17Abs');
                hideblock('zhangSensors17Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_wei_igta_2017.jpg" alt="Results of article_wei_igta_17" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Spacecraft Component Detection in Point Clouds</b> <a href="https://link.springer.com/chapter/10.1007/978-981-10-7389-2_21" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  <a href="https://weiquanmao.github.io" target="_blank">Quanmao Wei</a>, Zhiguo Jiang, Haopeng Zhang and Nie Shanlan
                </i></font>
                <br>
                IGTA, 2017
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="https://link.springer.com/content/pdf/10.1007%2F978-981-10-7389-2_21.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('weiIGTA17Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('weiIGTA17Bib')">BibTeX</a> &nbsp;
                <i class="fa fa-code"></i> <a href="https://github.com/weiquanmao/PCF" target="_blank">Code</a> &nbsp
              </p>
              <p id="weiIGTA17Abs" class="abstract" style="display: none;">
                Component detection of spacecraft is significant for on-orbit operation and space situational awareness. Solar wings and main body are the major components of most spacecrafts, and can be described by geometric primitives like planes, cuboid or cylinder. Based on this prior, pipeline to automatically detect the basic components of spacecraft in 3D point clouds is presented, in which planes, cuboid and cylinder are successively detected. The planar patches are first detected as possible solar wings in point clouds of the recorded object. As for detection of the main body, inferring a cuboid main body from the detected patches is first attempted, and a further attempt to extract a cylinder main body is made if no cuboid exists. Dimensions are estimated for each component. Experiments on satellite point cloud data that are recovered by image-based reconstruction demonstrated effectiveness and accuracy of this pipeline.
              </p>
              <pre xml:space="preserve" id="weiIGTA17Bib" class="bibtex" style="display: none;">
@inproceedings{weiIGTA17,
  author    = {Quanmao Wei and Zhiguo Jiang and Haopeng Zhang and Shanlan Nie},
  editor    = {Yongtian Wang and Shengjin Wang and Yue Liu and Jian Yang
               and Xiaoru Yuan and Ran He and Henry Been-Lirn Duh},
  title     = {Spacecraft Component Detection in Point Clouds},
  booktitle = {Advances in Image and Graphics Technologies},
  year      = {2017},
  publisher = {Springer Singapore},
  address   = {Singapore},
  pages     = {210—-218},
  isbn      = {978-981-10-7389-2}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('weiIGTA17Abs');
                hideblock('weiIGTA17Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_cai_rs_2017.jpg" alt="flowchart_of_cai_rs_17" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Airport Detection Using End-to-End Convolutional Neural Network with Hard Example Mining</b> <a href="http://www.mdpi.com/2072-4292/9/11/1198" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Bowen Cai, Zhiguo Jiang, Haopeng Zhang, Danpei Zhao and Yuan Yao
                </i></font>
                <br>
                Remote Sensing, 2017
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="http://www.mdpi.com/2072-4292/9/11/1198/pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('caiRS2017Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('caiRS2017Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="caiRS2017Abs" class="abstract" style="display: none;">
                  Deep convolutional neural network (CNN) achieves outstanding performance in the field of target detection. As one of the most typical targets in remote sensing images (RSIs), airport has attracted increasing attention in recent years. However, the essential challenge for using deep CNN to detect airport is the great imbalance between the number of airports and background examples in large-scale RSIs, which may lead to over-fitting. In this paper, we develop a hard example mining and weight-balanced strategy to construct a novel end-to-end convolutional neural network for airport detection. The initial motivation of the proposed method is that backgrounds contain an overwhelming number of easy examples and a few hard examples. Therefore, we design a hard example mining layer to automatically select hard examples by their losses, and implement a new weight-balanced loss function to optimize CNN. Meanwhile, the cascade design of proposal extraction and object detection in our network releases the constraint on input image size and reduces spurious false positives. Compared with geometric characteristics and low-level manually designed features, the hard example mining based network could extract high-level features, which is more robust for airport detection in complex environment. The proposed method is validated on a multi-scale dataset with complex background collected from Google Earth. The experimental results demonstrate that our proposed method is robust, and superior to the state-of-the-art airport detection models.
              </p>
              <pre xml:space="preserve" id="caiRS2017Bib" class="bibtex" style="display: none;">
@article{caiRS17,
  author  = {Bowen Cai and Zhiguo Jiang and Haopeng Zhang and Danpei Zhao and Yuan Yao},
  title   = {Airport Detection Using End-to-End Convolutional Neural Network
             with Hard Example Mining},
  journal = {Remote Sensing},
  volume  = {9},
  year    = {2017},
  number  = {11},
  article number = {1198},
  url     = {http://www.mdpi.com/2072-4292/9/11/1198},
  issn    = {2072-4292},
  doi     = {10.3390/rs9111198}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('caiRS2017Abs');
                hideblock('caiRS2017Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_cai_igarss_2017.jpg" alt="flowchart_of_cai_igarss_17" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Training Deep Convolution Neural Network with Hard Example Mining for Airport Detection</b> <a href="http://ieeexplore.ieee.org/document/8127089/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Bowen Cai, Zhiguo Jiang, Haopeng Zhang, Yuan Yao and Jie Huang
                </i></font>
                <br>
                IGARSS, 2017
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8127089" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('caiIGARSS2017Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('caiIGARSS2017Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="caiIGARSS2017Abs" class="abstract" style="display: none;">
                The geometrical characteristic and low-level manually designed features are usually used to detect airports in optical remote sensing images. But it is insufficient to describe airport in low resolution and illumination environment. This paper presents a hard example mining algorithm to train the end-to-end deep convolutional neural network for airport detection in complex situation. Compared with conventional airport detection methods which design specific low-level manually designed features for high-resolution remote sensing images, an end-to-end network can mine the general characteristic among the training samples and learn high-level features in multi-scale and multi-view remote sensing images. Meanwhile, an automatic hard example mining principle is introduced to make training more efficiently and accurately. The proposed method is validated on a multi-scale and multi-view dataset collected from Google Earth. The experimental results demonstrate that the proposed method is robust and efficient, and superior to the state-of-the-art airport detection models.
              </p>
              <pre xml:space="preserve" id="caiIGARSS2017Bib" class="bibtex" style="display: none;">
@inproceedings{caiIGARSS17,
  author    = {Bowen Cai and Zhiguo Jiang and Haopeng Zhang and Yuan Yao and Jie Huang},
  booktitle = {2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
  title     = {Training Deep Donvolution Neural Network
               with Hard Example Mining for Airport Detection},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {862—-865},
  doi       = {10.1109/IGARSS.2017.8127089},
  issn      = {},
  month     = {July}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('caiIGARSS2017Abs');
                hideblock('caiIGARSS2017Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_zheng_spiemi_2017.jpg" alt="Flowchart" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Content-based Histopathological Image Retrieval for Whole Slide Image Database Using Binary Codes</b> <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10140/1/Content-based-histopathological-image-retrieval-for-whole-slide-image-database/10.1117/12.2253988.full?SSO=1" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yushan Zheng, Zhiguo Jiang, Yibing Ma, Haopeng Zhang, Fengying Xie, Huaqiang Shi and Yu Zhao
                </i></font>
                <br>
                SPIE MI, 2017
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="source/pdf/article_zheng_spiemi_2017.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhengSPIEMI2017Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhengSPIEMI2017Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhengSPIEMI2017Abs" class="abstract" style="display: none;">
                Content-based image retrieval (CBIR) has been widely researched for medical images. In application of histo- pathological images, there are two issues that need to be carefully considered. The one is that the digital slide is stored in a spatially continuous image with a size of more than 10K x 10K pixels. The other is that the size of query image varies in a large range according to different diagnostic conditions. It is a challenging work to retrieve the eligible regions for the query image from the database that consists of whole slide images (WSIs). In this paper, we proposed a CBIR framework for the WSI database and size-scalable query images. Each WSI in the database is encoded and stored in a matrix of binary codes. When retrieving, the query image is first encoded into a set of binary codes and analyzed to pre-choose a set of regions from database using hashing method. Then a multi-binary-code-based similarity measurement based on hamming distance is designed to rank proposal regions. Finally, the top relevant regions and their locations in the WSIs along with the diagnostic information are returned to assist pathologists in diagnoses. The effectiveness of the proposed framework is evaluated in a fine-annotated WSIs database of epithelial breast tumors. The experimental results show that proposed framework is both effective and efficiency for content-based whole slide image retrieval.
              </p>
              <pre xml:space="preserve" id="zhengSPIEMI2017Bib" class="bibtex" style="display: none;">
@inproceedings{zhengSPIEME17,
  title     = {Content-based Histopathological Image Retrieval
               for Whole Slide Image Database Using Binary Codes},
  author    = {Yushan Zheng and Zhiguo Jiang and Yibing Ma and Haopeng Zhang
               and Fengying Xie and Huaqiang Shi and Yu Zhao},
  booktitle = {SPIE Medical Imaging},
  doi       = {doi.org/10.1117/12.2253988},
  pages     = {1014013},
  year      = {2017}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhengSPIEMI2017Abs');
                hideblock('zhengSPIEMI2017Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
        </tbody></table>

        <hr />
        <!-- -------------------------------------------- -->
        <!-- -------------------------------------------- -->
        <h3>2016</h3>
        <table><tbody>
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/airticle_wu_igarss_2016.jpg" alt="Flowchart" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Semi-supervised Conditional Random Field for hyperspectral remote sensing image classification</b> <a href="https://ieeexplore.ieee.org/document/7729675/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                    Junfeng Wu, Zhiguo Jiang, Haopeng Zhang, Bowen Cai and Quanmao Wei
                </i></font>
                <br>
                IGARSS,2016
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="source\pdf\article_wu_igarss_2016.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('wuIGARSS2016Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('wuIGARSS2016Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="wuIGARSS2016Abs" class="abstract" style="display: none;">
                  <b>Conditional Random Field</b>(CRF) has been successfully applied to the <b>hyperspectral image classification</b>. However, it suffers from the availability of large amount of labeled pixels, which is labor- and time-consuming to obtain in practice. In this paper, a semi-supervised CRF(ssCRF) is proposed <b>for hyperspectral image classification</b> with limited labeled pixels. Laplacian Support Vector Machine(LapSVM), after extended into the composite kernel type, is defined as the association potential. And the Potts model is utilized as the interaction potential. The ssCRF is evaluated on the two benchmarks and the results show the effectiveness of ssCRF.
              </p>
              <pre xml:space="preserve" id="wuIGARSS2016Bib" class="bibtex" style="display: none;">
@inproceedings{zhengSPIEME17,
  title     = {Semi-supervised Conditional Random Field for hyperspectral remote sensing image classification},
  author    = {Junfeng Wu and Zhiguo Jiang and Haopeng Zhang and Bowen Cai and Quanmao Wei},
  booktitle = {2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
  doi       = {10.1109/IGARSS.2016.7729675},
  pages     = {2614-2617},
  year      = {2016}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('wuIGARSS2016Abs');
                hideblock('wuIGARSS2016Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_ma_cmpb_2018.jpg" alt="Result" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Breast Histopathological Image Retrieval Based on Latent Dirichlet Allocation</b> <a href="http://ieeexplore.ieee.org/document/7572100/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                    Yibing Ma, Zhiguo Jiang, Haopeng Zhang, Fengying Xie, Yushan Zheng, Huaqiang Shi and Yu Zhao
                </i></font>
                <br>
                  JBHI, 2016
                <br>
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('maJBHI2016Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('maCMBP2018Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="maJBHI2016Abs" class="abstract" style="display: none;">
                  In the field of pathology, whole slide image (WSI) has become the major carrier of visual and diagnostic information. Content-based image retrieval among WSIs can aid the diagnosis of an unknown pathological image by finding its similar regions in WSIs with diagnostic information. However, the huge size and complex content of WSI pose several challenges for retrieval. In this paper, we propose an unsupervised, accurate, and fast retrieval method for a breast histopathological image. Specifically, the method presents a local statistical feature of nuclei for morphology and distribution of nuclei, and employs the Gabor feature to describe the texture information. The latent Dirichlet allocation model is utilized for high-level semantic mining. Locality-sensitive hashing is used to speed up the search. Experiments on a WSI database with more than 8000 images from 15 types of breast histopathology demonstrate that our method achieves about 0.9 retrieval precision as well as promising efficiency. Based on the proposed framework, we are developing a search engine for an online digital slide browsing and retrieval platform, which can be applied in computer-aided diagnosis, pathology education, and WSI archiving and management.
                </p>
              <pre xml:space="preserve" id="maCMBP2018Bib" class="bibtex" style="display: none;">
@article{maJBHI2016, 
  author  = {Yibing Ma and Zhiguo Jiang and Haopeng Zhang and Fengying Xie 
             and Yushan Zheng and Huaqiang Shi and Yu Zhao and Jun Shi}, 
  journal = {IEEE Journal of Biomedical and Health Informatics}, 
  title   = {Breast Histopathological Image Retrieval Based on Latent Dirichlet Allocation}, 
  year    = {2017}, 
  volume  = {21}, 
  number  = {4}, 
  pages   = {1114-1123}, 
  doi     = {10.1109/JBHI.2016.2611615}, 
  ISSN    = {2168-2194}, 
  month   = {July}
}    
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('maJBHI2016Abs');
                hideblock('maCMBP2018Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_zhang_igta_2016.jpg" alt="Results of article_zhang_igta_16" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Pose Estimation of Space Objects Based on Hybrid Feature Matching of Contour Points</b> <a href="https://link.springer.com/chapter/10.1007/978-981-10-2260-9_21" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Xin Zhang, Haopeng Zhang, <a href="https://weiquanmao.github.io" target="_blank">Quanmao Wei</a> and Zhiguo Jiang
                </i></font>
                <br>
                IGTA, 2016
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="https://link.springer.com/content/pdf/10.1007%2F978-981-10-2260-9_21.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhangIGTA16Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhangIGTA16Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhangIGTA16Abs" class="abstract" style="display: none;">
                This paper presents an improved pose estimation algorithm for vision-based space objects. The major weakness of most existing methods is limited convergence radius. In most cases they ignore the influence of translation, only focusing on rotation parameters. To breakthrough these limits, we utilizes hybrid local image features to explicitly establish 2D-3D correspondences between the input image and 3D model of space objects, and then estimate rotation and translation parameters based on the correspondences. Experiments with simulated models are carried out, and the results show that our algorithm can successfully estimate the pose of space objects with large convergence radius and high accuracy.
              </p>
              <pre xml:space="preserve" id="zhangIGTA16Bib" class="bibtex" style="display: none;">
@inproceedings{zhangIGTA16,
  author    = {Xin Zhang and Haopeng Zhang and Quanmao Wei and Zhiguo Jiang},
  editor    = {Tieniu Tan and Guoping Wang and Shengjin Wang and Yue Liu
               and Xiaoru Yuan and Ran He and Sheng Li},
  title     = {Pose Estimation of Space Objects Based on Hybrid Feature Matching
               of Contour Points},
  booktitle = {Advances in Image and Graphics Technologies},
  year      = {2016},
  publisher = {Springer Singapore},
  address   = {Singapore},
  pages     = {184—-191},
  isbn      = {978-981-10-2260-9}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhangIGTA16Abs');
                hideblock('zhangIGTA16Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_zhang_jbuaa_2016.jpg" alt="Results of article_zhang_jbuaa_16" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Sequential-image-based Space Object 3D Reconstruction</b> <a href="http://doi.cnki.net/Resolution/Handler?doi=10.13700/j.bh.1001-5965.2015.0117" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Haopeng Zhang, <a href="https://weiquanmao.github.io" target="_blank">Quanmao Wei</a>, Wei Zhang, Junfeng Wu and Zhiguo Jiang
                </i></font>
                <br>
                JBUAA, 2016 <i>[In Chinese]</i>
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="http://bhxb.buaa.edu.cn/CN/article/downloadArticleFile.do?attachType=PDF&id=13381" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhangJBUAA16Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhangJBUAA16Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhangJBUAA16Abs" class="abstract" style="display: none;">
                Space object 3D reconstruction is of important significance for both space situational awareness and theoretical study. A new structure from motion method was proposed to avoid the reconstruction error caused by the symmetrical structure and similar texture of space targets. In this method, new images were added sequentially for reconstruction using the imaging time as a priori knowledge. In addition, image simulation of space target and ground imaging simulation experiment were carried out for the lack of space target image data. And experiments on the simulated space target images, in which the motion analysis results are accurate and robust to noise, and the recovery 3D point cloud can express the structural information of the target to a certain extent, have demonstrated the effectiveness of the approach proposed, and the boundary conditions of multi-frame-image for 3D reconstruction are acquired as well.
              </p>
              <pre xml:space="preserve" id="zhangJBUAA16Bib" class="bibtex" style="display: none;">
@article{zhangJBUAA16,
  language = {Chinse},
  author   = {Haopeng Zhang and Quanmao Wei and Wei Zhang and Junfeng Wu and Zhiguo Jiang},
  title    = {Sequential-image-based Space Object 3D Reconstruction},
  journal  = {Journal of Beijing University of Aeronautics and Astronautics},
  year     = {2016},
  volume   = {42},
  number   = {2},
  pages    = {273--279},
  issn     = {10015965},
  URL      = {http://dx.doi.org/10.13700/j.bh.1001-5965.2015.0117}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhangJBUAA16Abs');
                hideblock('zhangJBUAA16Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_yao_igarss_2016.jpg" alt="Results of article_yao_igarss_2016" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>High-resolution Optical Satellite Image Simulation of Ship Target in Large Sea Scenes</b> <a href="http://ieeexplore.ieee.org/document/7729314/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yuan Yao, Zhiguo Jiang and Haopeng Zhang
                </i></font>
                <br>
                IGRASS, 2016
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="source/pdf/article_yao_igarss_2016.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('yaoIGARSS16Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('yaoIGARSS16Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="yaoIGARSS16Abs" class="abstract" style="display: none;">
                Ship target detection in optical remote sensing images has attracted more and more attention in the field of remote sensing. The ship target detection technology of optical remote sensing images is vulnerable to many factors, while the real data are difficult to contain various elements. In order to obtain the various situations in the large sea scenes, we develop a simulation system for high-resolution optical remote sensing image of ship targets. The simulated images with different sea states, cloud conditions, target types and imaging conditions can support the evaluation and comparison of ship detection algorithms as well as other tasks in remote sensing image analysis.
              </p>
              <pre xml:space="preserve" id="yaoIGARSS16Bib" class="bibtex" style="display: none;">
@inproceedings{yaoIGARSS16,
  author    = {Yuan Yao and Zhiguo Jiang and Haopeng Zhang},
  booktitle = {2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
  title     = {High-resolution Optical Satellite Image Simulation of Ship Target
               in Large Sea Scenes},
  year      = {2016},
  month     = {July},
  volume    = {},
  number    = {},
  pages     = {1241—-1244},
  doi       = {10.1109/IGARSS.2016.7729314}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('yaoIGARSS16Abs');
                hideblock('yaoIGARSS16Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
        </tbody></table>

        <hr />
        <!-- -------------------------------------------- -->
        <!-- -------------------------------------------- -->
        <h3>2015</h3>
        <table><tbody>
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_Haopeng_sci_2015.jpg" alt="Result" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Satellite recognition and pose estimation using homeomorphic manifold analysis</b> <a href="https://ieeexplore.ieee.org/document/7073533/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                   Zhang H, Jiang Z, Elgammal A
                </i></font>
                <br>
                  TAES, 2015
                <br>
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('HaopengSCI2015Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('HaopengSCI2015Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="HaopengSCI2015Abs" class="abstract" style="display: none;">
                We propose a novel monocular vision-based framework for both satellite recognition and pose estimation, using homeomorphic manifold analysis. We use a unified conceptual manifold to represent continuous pose variation of all satellites in the visual input space, learn nonlinear function mapping from conceptual manifold representation to visual inputs, and decompose discrete category variation in the mapping coefficient space. Experimental results on a simulated image data set show the effectiveness and robustness of our approach.
                </p>
              <pre xml:space="preserve" id="HaopengSCI2015Bib" class="bibtex" style="display: none;">
@article{HaopengSCI2015,
  title   = {Satellite recognition and pose estimation using homeomorphic manifold analysis},
  author  = {Zhang H, Jiang Z, Elgammal A},
  journal = {IEEE Transactions on Aerospace and Electronic Systems},
  pages   = {785 - 792},
  year    = {2015},
  issn    = {0018-9251},
  url     = {https://ieeexplore.ieee.org/document/7073533/},
}      
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('HaopengSCI2015Abs');
                hideblock('HaopengSCI2015Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_Haopeng_sci_2015_1.jpg" alt="Result" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b> Factorization of View-Object Manifolds for Joint Object Recognition and Pose Estimation</b> <a href="https://www.sciencedirect.com/science/article/pii/S1077314215000715?via%3Dihub" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                    Zhang H, El-Gaaly T, Elgammal A, Zhiguo Jiang
                </i></font>
                <br>
                  CVIU, 2015
                <br>
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('HaopengSCI2015_1Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('HaopengSCI2015_1Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="HaopengSCI2015_1Abs" class="abstract" style="display: none;">
                Due to large variations in shape, appearance, and viewing conditions, object recognition is a key precursory challenge in the fields of object manipulation and robotic/AI visual reasoning in general. Recognizing object categories, particular instances of objects and viewpoints/poses of objects are three critical subproblems robots must solve in order to accurately grasp/manipulate objects and reason about their environments. Multi-view images of the same object lie on intrinsic low-dimensional manifolds in descriptor spaces (e.g. visual/depth descriptor spaces). These object manifolds share the same topology despite being geometrically different. Each object manifold can be represented as a deformed version of a unified manifold. The object manifolds can thus be parameterized by its homeomorphic mapping/reconstruction from the unified manifold. In this work, we develop a novel framework to jointly solve the three challenging recognition sub-problems, by explicitly modeling the deformations of object manifolds and factorizing it in a view-invariant space for recognition. We perform extensive experiments on several challenging datasets and achieve state-of-the-art results.
                </p>
              <pre xml:space="preserve" id="HaopengSCI2015_1Bib" class="bibtex" style="display: none;">
@article{HaopengSCI2015,
  title   = {Factorization of View-Object Manifolds for Joint Object Recognition and Pose Estimation},
  author  = {Zhang H, El-Gaaly T, Elgammal A, Zhiguo Jiang},
  journal = {Computer Vision and Image Understanding},
  volume  = {139},
  pages   = {89 - 103},
  year    = {2015}
  url     = {https://www.sciencedirect.com/science/article/pii/S1077314215000715?via%3Dihub},
}      
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('HaopengSCI2015_1Abs');
                hideblock('HaopengSCI2015_1Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
        
        <tr> <!-- An Paper -->
          <td width="22%" valign="top"><p>
            <img src="images/src/article_Haopeng_sci_2015_2.jpg" alt="Result" width="200">
          </p></td>
          <td width="78%" valign="top">
            <p>
              <b> Vision-based pose estimation for space objects by Gaussian process regression</b> <a href="https://ieeexplore.ieee.org/document/7118908/" target="_blank"><i class="fa fa-external-link"></i></a>
              <br>
              <font size="3pt" face="Georgia"><i>
                  Zhang H, Jiang Z, Yao Y, et al
              </i></font>
              <br>
                AC, 2015
              <br>
              <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('HaopengSCI2015_2Abs')">Abstract</a> &nbsp;
              <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('HaopengSCI2015_2Bib')">BibTeX</a> &nbsp;
            </p>
            <p id="HaopengSCI2015_2Abs" class="abstract" style="display: none;">
                We address the problem of vision-based pose estimation for space objects, which is to estimate the relative pose of a target spacecraft using imaging sensors. We develop a novel monocular vision-based method by employing Gaussian process regression (GPR) to solve pose estimation for space objects. GPR is a powerful regression model for predicting continuous quantities, and can easily obtain and express uncertainty. Assuming that the regression function mapping from the image (or feature) of the target spacecraft to its pose follows a Gaussian process (GP) properly parameterized by a mean function and a covariance function, the predictive equations can be easily obtained by a maximum-likelihood approach when training data are given. The mean value of the predicted output (i.e. the estimated pose) and its variance (which indicates the uncertainty) can be computed via these explicit formulations. Besides, we also introduce a manifold constraint to the output of GPR model to improve its performance for spacecraft pose estimation. We performed extensive experiments on a simulated image dataset that contains satellite images of 1D and 2D pose variation, as well as images with noises and different lighting conditions. Experimental results validate the effectiveness and robustness of our approach. Our model can not only estimate the pose angles of space objects but also provide the uncertainty of the estimated values which may be used to choose convincing results in applications.
              </p>
            <pre xml:space="preserve" id="HaopengSCI2015_2Bib" class="bibtex" style="display: none;">
@article{HaopengSCI2015,
title   = {Vision-based pose estimation for space objects by Gaussian process regression},
author  = {Zhang H, Jiang Z, Yao Y, et al},
journal = {Aerospace Conference, 2015 IEEE},
pages   = {1 - 9},
year    = {2015},
doi     = {10.1109/AERO.2015.7118908},
issn    = {1095-323X}
url     = {https://ieeexplore.ieee.org/document/7118908/},
}      
            </pre>
            <script language="javascript" type="text/javascript" xml:space="preserve">
              hideblock('HaopengSCI2015_2Abs');
              hideblock('HaopengSCI2015_2Bib');
            </script>
          </td>
        </tr> <!-- Paper End Here -->
          
        </tbody></table>

        <hr />
        <!-- -------------------------------------------- -->
        <!-- -------------------------------------------- -->
        <h3>2014</h3>
        <table><tbody>
            <tr> <!-- An Paper -->
              <td width="22%" valign="top"><p>
                <img src="images/src/article_Haopeng_sci_2014.jpg" alt="Result" width="200">
              </p></td>
              <td width="78%" valign="top">
                <p>
                  <b> Multi-view space object recognition and pose estimation based on kernel regression</b> <a href="https://www.sciencedirect.com/science/article/pii/S1000936114000533" target="_blank"><i class="fa fa-external-link"></i></a>
                  <br>
                  <font size="3pt" face="Georgia"><i>
                      Zhang H, Jiang Z
                  </i></font>
                  <br>
                    CJA, 2014
                  <br>
                  <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('HaopengSCI2014Abs')">Abstract</a> &nbsp;
                  <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('HaopengSCI2014Bib')">BibTeX</a> &nbsp;
                </p>
                <p id="HaopengSCI2014Abs" class="abstract" style="display: none;">
                    We address the problem of vision-based pose estimation for space objects, which is to estimate the relative pose of a target spacecraft using imaging sensors. We develop a novel monocular vision-based method by employing Gaussian process regression (GPR) to solve pose estimation for space objects. GPR is a powerful regression model for predicting continuous quantities, and can easily obtain and express uncertainty. Assuming that the regression function mapping from the image (or feature) of the target spacecraft to its pose follows a Gaussian process (GP) properly parameterized by a mean function and a covariance function, the predictive equations can be easily obtained by a maximum-likelihood approach when training data are given. The mean value of the predicted output (i.e. the estimated pose) and its variance (which indicates the uncertainty) can be computed via these explicit formulations. Besides, we also introduce a manifold constraint to the output of GPR model to improve its performance for spacecraft pose estimation. We performed extensive experiments on a simulated image dataset that contains satellite images of 1D and 2D pose variation, as well as images with noises and different lighting conditions. Experimental results validate the effectiveness and robustness of our approach. Our model can not only estimate the pose angles of space objects but also provide the uncertainty of the estimated values which may be used to choose convincing results in applications.
                  </p>
                <pre xml:space="preserve" id="HaopengSCI2014Bib" class="bibtex" style="display: none;">
    @article{HaopengSCI2015,
    title   = {Multi-view space object recognition and pose estimation based on kernel regression},
    author  = {Zhang H, Jiang Z},
    journal = {Chinese Journal of Aeronautics},
    pages   = {1233 - 1241},
    year    = {2014},
    volume  = {27},
    url     = {https://www.sciencedirect.com/science/article/pii/S1000936114000533},
    }      
                </pre>
                <script language="javascript" type="text/javascript" xml:space="preserve">
                  hideblock('HaopengSCI2014Abs');
                  hideblock('HaopengSCI2014Bib');
                </script>
              </td>
            </tr> <!-- Paper End Here -->
            <tr> <!-- An Paper -->
              <td width="22%" valign="top"><p>
                <img src="images/src/article_Haopeng_sci_2014_1.jpg" alt="Result" width="200">
              </p></td>
              <td width="78%" valign="top">
                <p>
                  <b> Manifold representation of multi-view images</b> <a href="https://www.researchgate.net/publication/288287272_Manifold_representation_of_multi-view_images" target="_blank"><i class="fa fa-external-link"></i></a>
                  <br>
                  <font size="3pt" face="Georgia"><i>
                      Zhang, Haopeng, Jiang, Zhiguo
                  </i></font>
                  <br>
                    JCIS, 2014
                  <br>
                  <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('HaopengSCI2014_1Abs')">Abstract</a> &nbsp;
                  <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('HaopengSCI2014_1Bib')">BibTeX</a> &nbsp;
                </p>
                <p id="HaopengSCI2014_1Abs" class="abstract" style="display: none;">
                    We address the problem of vision-based pose estimation for space objects, which is to estimate the relative pose of a target spacecraft using imaging sensors. We develop a novel monocular vision-based method by employing Gaussian process regression (GPR) to solve pose estimation for space objects. GPR is a powerful regression model for predicting continuous quantities, and can easily obtain and express uncertainty. Assuming that the regression function mapping from the image (or feature) of the target spacecraft to its pose follows a Gaussian process (GP) properly parameterized by a mean function and a covariance function, the predictive equations can be easily obtained by a maximum-likelihood approach when training data are given. The mean value of the predicted output (i.e. the estimated pose) and its variance (which indicates the uncertainty) can be computed via these explicit formulations. Besides, we also introduce a manifold constraint to the output of GPR model to improve its performance for spacecraft pose estimation. We performed extensive experiments on a simulated image dataset that contains satellite images of 1D and 2D pose variation, as well as images with noises and different lighting conditions. Experimental results validate the effectiveness and robustness of our approach. Our model can not only estimate the pose angles of space objects but also provide the uncertainty of the estimated values which may be used to choose convincing results in applications.
                  </p>
                <pre xml:space="preserve" id="HaopengSCI2014_1Bib" class="bibtex" style="display: none;">
    @article{HaopengSCI2015,
    title   = {Manifold representation of multi-view images},
    author  = {Zhang, Haopeng, Jiang, Zhiguo},
    journal = {Journal of Computational Information Systems},
    pages   = {4867 - 4876},
    year    = {2014},
    doi     = {10.12733/jcis10624},
    url     = {https://www.researchgate.net/publication/288287272_Manifold_representation_of_multi-view_images},
    }      
                </pre>
                <script language="javascript" type="text/javascript" xml:space="preserve">
                  hideblock('HaopengSCI2014_1Abs');
                  hideblock('HaopengSCI2014_1Bib');
                </script>
              </td>
            </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_zheng_icip_2014.jpg" alt="Flowchart" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Retrieval of Pathology Image for Breast Cancer Using PLSA Model Based on Texture and Pahological Features</b> <a href="http://xueshu.baidu.com/s?wd=paperuri%3A%280ffc62d136826578e27817d048608818%29&filter=sc_long_sign&tn=SE_xueshusource_2kduw22v&sc_vurl=http%3A%2F%2Fdx.doi.org%2F10.1109%2Ficip.2014.7025467&ie=utf-8&sc_us=1281695813514094042" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yushan Zheng, Zhiguo Jiang, Jun Shi and Yibing Ma
                </i></font>
                <br>
                ICIP, 2014
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="source/pdf/article_zheng_icip_2014.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhengICIP2014Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhengICIP2014Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhengICIP2014Abs" class="abstract" style="display: none;">
                Content-based image retrieval (CBIR) for digital pathology slides is of clinical use for breast cancer aided diagnosis. One of the largest challenges in CBIR is feature extraction. In this paper, we propose a novel pathology image retrieval method for breast cancer, which aims to characterize the pathology image content through texture and pathological features and further discover the latent high-level semantics. Specifically, the proposed method utilizes block Gabor features to describe the texture structure, and simultaneously designs nucleus-based pathological features to describe morphological characteristics of nuclei. Based on these two kinds of local feature descriptors, two codebooks are built to learn the probabilistic latent semantic analysis (pLSA) models. Consequently, each image is represented by the topics of pLSA models which can reveal the semantic concepts. Experimental results on the digital pathology image database for breast cancer demonstrate the feasibility and effectiveness of our method.
              </p>
              <pre xml:space="preserve" id="zhengICIP2014Bib" class="bibtex" style="display: none;">
@article{zhengICIP14,
  title     = {Retrieval of Pathology Image for Breast Cancer Using PLSA Model
               Based on Texture and Pathological Features},
  author    = {Yushan Zheng and Zhiguo Jiang and Jun Shi and Yibing Ma},
  booktitle = {2016 IEEE International Conference on Image Processing (ICIP)},
  pages     = {2304--2308},
  year      = {2014}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhengICIP2014Abs');
                hideblock('zhengICIP2014Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="images/src/article_zheng_igta_2014.jpg" alt="Flowchart" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Pathology Image Retrieval by Block LBP Based PLSA Model with Low-Rank and Sparse Matrix Decomposition</b> <a href="https://link.springer.com/chapter/10.1007/978-3-662-45498-5_36" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yushan Zheng, Zhiguo Jiang, Jun Shi and Yibing Ma
                </i></font>
                <br>
                IGTA, 2014
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="source/pdf/article_zheng_igta_2014.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhengIGTA2014Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhengIGTA2014Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhengIGTA2014Abs" class="abstract" style="display: none;">
                Content-based image retrieval (CBIR) is widely used in Computer Aided Diagnosis (CAD) systems which can aid pathologist to make reasonable decision by querying the slides with diagnostic information from the digital pathology slide database. In this paper, we propose a novel pathology image retrieval method for breast cancer. It firstly applies block Local Binary Pattern (LBP) features to describe the spatial texture property of pathology image, and then use them to construct the probabilistic latent semantic analysis (pLSA) model which generally takes advantage of visual words to mine the topic-level representation of image and thus reveals the high-level semantics. Different from conventional pLSA model, we employ low-rank and sparse matrix composition for describing the correlated and specific characteristics of visual words. Therefore, the more discriminative topic-level representation corresponding to each pathology image can be obtained. Experimental results on the digital pathology image database for breast cancer demonstrate the feasibility and effectiveness of our method.
              </p>
              <pre xml:space="preserve" id="zhengIGTA2014Bib" class="bibtex" style="display: none;">
@inproceedings{zhengIGTA14,
  title     = {Pathology Image Retrieval by Block LBP Based PLSA Model
               with Low-Rank and Sparse Matrix Decomposition},
  author    = {Yushan Zheng and Zhiguo Jiang and Jun Shi and Yibing Ma},
  booktitle = {Advances in Image and Graphics Technologies},
  pages     = {327—-335},
  year      = {2014}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhengIGTA2014Abs');
                hideblock('zhengIGTA2014Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="i" alt="Image" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Regularized least square discriminant projection and feature selection</b> <a href="https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging/volume-23/issue-01/013003/Regularized-least-square-discriminant-projection-and-feature-selection/10.1117/1.JEI.23.1.013003.full" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Jun Shi, Zhiguo Jiang, Danpei Zhao, Hao Feng, Chao Gao
                </i></font>
                <br>
                JEI, 2014
                <br>
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('shiJEI2014Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('shiJEI2014Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="shiJEI2014Abs" class="abstract" style="display: none;">
                  Conventional graph embedding framework uses the Euclidean distance to determine the similarities of neighbor samples, which causes the graph structure to be sensitive to outliers and lack physical interpretation. Moreover, the graph construction suffers from the difficulty of neighbor parameter selection. Although sparse representation (SR) based graph embedding methods can automatically select the neighbor parameter, the computational cost of SR is expensive. On the other hand, most discriminant projection methods fail to perform feature selection. In this paper, we present a novel joint discriminant analysis and feature selection method that employs regularized least square for graph construction and l 2; 1-norm minimization on projection matrix for feature selection. Specifically, our method first uses the regularized least square coefficients to measure the intraclass and interclass similarities from the viewpoint of reconstruction. Based on this graph structure, we formulate an object function with scatter difference criterion for learning the discriminant projections, which can avoid the small sample size problem. Simultaneously, the l2; 1-norm minimization on projection matrix is applied to gain row-sparsity for selecting useful features. Experiments on two face databases (ORL and AR) and COIL-20 object database demonstrate that our method not only achieves better classification performance, but also has lower computational cost than SR. (C) 2014 SPIE and IS&T
                </p>
              <pre xml:space="preserve" id="shiJEI2014Bib" class="bibtex" style="display: none;">
@article{shiJEI2014,
  author  = {Jun Shi and Zhiguo Jiang and Danpei Zhao and Hao Feng and Chao Gao},
  title   = {Regularized least square discriminant projection and feature selection},
  journal = {Journal of Electronic Imaging},
  volume  = {23},
  pages   = {23 - 23 - 15},
  year    = {2014},
  doi     = {10.1117/1.JEI.23.1.013003},
  URL     = {https://doi.org/10.1117/1.JEI.23.1.013003},
}             
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('shiJEI2014Abs');
                hideblock('shiJEI2014Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="i" alt="Image" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Adaptive Graph Embedding Discriminant Projections</b> <a href="https://link.springer.com/article/10.1007%2Fs11063-013-9323-8" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Jun Shi, Zhiguo Jiang and Hao Feng
                </i></font>
                <br>
                NPL, 2014
                <br>
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('shiNPL2014Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('shiNPL2014Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="shiNPL2014Abs" class="abstract" style="display: none;">
                  Graph embedding based learning method plays an increasingly significant role on dimensionality reduction (DR). However, the selection to neighbor parameters of graph is intractable. In this paper, we present a novel DR method called adaptive graph embedding discriminant projections (AGEDP). Compared with most existing DR methods based on graph embedding, such as marginal Fisher analysis which usually predefines the intraclass and interclass neighbor parameters, AGEDP applies all the homogeneous samples for constructing the intrinsic graph, and simultaneously selects heterogeneous samples within the neighborhood generated by the farthest homogeneous sample for constructing the penalty graph. Therefore, AGEDP not only greatly enhances the intraclass compactness and interclass separability, but also adaptively performs neighbor parameter selection which considers the fact that local manifold structure of each sample is generally different. Experiments on AR and COIL-20 datasets demonstrate the effectiveness of the proposed method for face recognition and object categorization, and especially under the interference of occlusion, noise and poses, it is superior to other graph embedding based methods with three different classifiers: nearest neighbor classifier, sparse representation classifier and linear regression classifier.
                </p>
              <pre xml:space="preserve" id="shiNPL2014Bib" class="bibtex" style="display: none;">
@Article{ShiNPL2014,
  author  = {Jun Shi and Zhiguo Jiang and Hao Feng},
  title   = {Adaptive Graph Embedding Discriminant Projections},
  journal = {Neural Processing Letters},
  year    = {2014},
  volume  = {40},
  number  = {3},
  pages   = {211--226},
  doi     = {10.1007/s11063-013-9323-8},
}     
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('shiNPL2014Abs');
                hideblock('shiNPL2014Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
        </tbody></table>

        <hr />
        <!-- -------------------------------------------- -->
        <!-- -------------------------------------------- -->
        <h3>2013</h3>
        <table><tbody>
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="i" alt="Image" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Unsupervised texture segmentation based on latent topic assignment</b> <a href="https://www.spiedigitallibrary.org/journals/Journal-of-Electronic-Imaging/volume-22/issue-01/013026/Unsupervised-texture-segmentation-based-on-latent-topic-assignment/10.1117/1.JEI.22.1.013026.full?SSO=1" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Hao Feng, Zhiguo Jiang and Jun Shi
                </i></font>
                <br>
                JEI, 2013
                <br>
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('fengJEI2013Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('fengJEI2013Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="fengJEI2013Abs" class="abstract" style="display: none;">
                We present an effective solution for unsupervised texture segmentation by taking advantage of the latent Dirichlet allocation (LDA) model. LDA is a generative topic model that is capable of hierarchically organizing discrete data including texts and images. We propose a new texture model by connecting texture primitives to the topic of LDA. The model is able to extract the characteristic features of a texture primitive and group them into a topic based on their frequencies of co-occurrence. Here, the feature descriptor is the connection of Haar-like features of multiple sizes. The segments of an image are finally obtained by identifying the homogeneous regions in the corresponding topic assignment map. The evaluation results for synthetic texture mosaics, remote sensing images, and natural scene images are illustrated.
              </p>
              <pre xml:space="preserve" id="fengJEI2013Bib" class="bibtex" style="display: none;">
@article{fengJEI2013,
  author  = {Hao  Feng and Zhiguo Jiang and Jun  Shi},
  title   = {Unsupervised texture segmentation based on latent topic assignment},
  journal = {Journal of Electronic Imaging},
  volume  = {22},
  number  = {1},
  pages   = {13-26},
  year    = {2013},
  doi     = {10.1117/1.JEI.22.1.013026},
  URL     = {https://doi.org/10.1117/1.JEI.22.1.013026},
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('fengJEI2013Abs');
                hideblock('fengJEI2013Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="i" alt="Image" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Pathological Image Retrieval for Breast Cancer with pLSA Model</b> <a href="http://ieeexplore.ieee.org/document/6643748/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Jun Shi, Yibing Ma, Zhiguo Jiang, Hao Feng, Jin Chen and Yu Zhao
                </i></font>
                <br>
                ICIG, 2013
                <br>
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('shiICIG2013Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('shiICIG2013Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="shiICIG2013Abs" class="abstract" style="display: none;">
                Pathological image retrieval contributes to computer-aided diagnosis for breast cancer due to the fact that the retrieval results generally contain detailed diagnostic information (e.g. abnormal regions and diagnostic opinion from other doctors) which can offer some reference and assistance to the doctor during diagnosis process. In this paper, we present a novel pathological image retrieval approach based on probabilistic latent semantic analysis (pLSA) model. The method respectively utilizes SIFT features after visual saliency detection, and block Gabor features for the construction of two semantic codebooks, which not only can characterize the salient local invariant features and texture information under different scales and orientations in the pathological images, but also consider the high-level semantic features. Furthermore, we apply pLSA model to discover the latent topics in each codebook. Finally each pathological image is represented by the combination of topics from these two codebooks. The proposed method is evaluated on the pathological image database for breast cancer, which includes 5 categories (mucinous cystadenocarcinoma, invasive lobular carcinoma, basal-like carcinoma, invasive breast cancer and low-grade adenosquamous carcinoma) and 110 cases for each category. Experimental results demonstrate the feasibility and effectiveness of our method.
              </p>
              <pre xml:space="preserve" id="shiICIG2013Bib" class="bibtex" style="display: none;">
@inproceedings{shiICIG2013, 
  author    = {Jun Shi and Yibing Ma and Zhiguo Jiang and Hao Feng and Jin Chen and Yu Zhao}, 
  booktitle = {2013 Seventh International Conference on Image and Graphics}, 
  title     = {Pathological Image Retrieval for Breast Cancer with pLSA Model}, 
  year      = {2013}, 
  pages     = {634-638}, 
  doi       = {10.1109/ICIG.2013.131},
  month     = {July}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('shiICIG2013Abs');
                hideblock('shiICIG2013Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="i" alt="Image" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>PLSA-based pathological image retrieval for breast cancer with color deconvolution</b> <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/8920/1/PLSA-based-pathological-image-retrieval-for-breast-cancer-with-color/10.1117/12.2032054.full" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yibing Ma, Jun Shi, Zhiguo Jiang and Hao Feng
                </i></font>
                <br>
                ICIG, 2013
                <br>
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('maMIPPR2013Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('maMIPPR2013Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="maMIPPR2013Abs" class="abstract" style="display: none;">
                Digital pathological image retrieval plays an important role in computer-aided diagnosis for breast cancer. The retrieval results of an unknown pathological image, which are generally previous cases with diagnostic information, can provide doctors with assistance and reference. In this paper, we develop a novel pathological image retrieval method for breast cancer, which is based on stain component and probabilistic latent semantic analysis (pLSA) model. Specifically, the method firstly utilizes color deconvolution to gain the representation of different stain components for cell nuclei and cytoplasm, and then block Gabor features are conducted on cell nuclei, which is used to construct the codebook. Furthermore, the connection between the words of the codebook and the latent topics among images are modeled by pLSA. Therefore, each image can be represented by the topics and also the high-level semantic concepts of image can be described. Experiments on the pathological image database for breast cancer demonstrate the effectiveness of our method.
              </p>
              <pre xml:space="preserve" id="maMIPPR2013Bib" class="bibtex" style="display: none;">
@proceeding{maMIPPR2013,
  author  = {Yibing Ma and Jun Shi and Zhiguo Jiang and Hao Feng},
  title   = {PLSA-based pathological image retrieval for breast cancer with color deconvolution},
  journal = {Proc.SPIE},
  volume  = {8920},
  pages   = {8920-7},
  year    = {2013},
  doi     = {10.1117/12.2032054},
  URL     = {https://doi.org/10.1117/12.2032054},
}          
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('maMIPPR2013Abs');
                hideblock('maMIPPR2013Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="i" alt="Image" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Sparse coding-based topic model for remote sensing image segmentation</b> <a href="http://ieeexplore.ieee.org/document/6723740/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Jun Shi, Zhiguo Jiang, Hao Feng and Yibing Ma
                </i></font>
                <br>
                IGARSS, 2013
                <br>
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('shiIGARSS2013Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('shiIGARSS2013Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="shiIGARSS2013Abs" class="abstract" style="display: none;">
                Land cover segmentation can be viewed as topic assignment that the pixels are grouped into homogeneous regions according to different semantic topics in topic model. In this paper, we propose a novel topic model based on sparse coding for segmenting different kinds of land covers. Different from conventional topic models which generally assume each local feature descriptor is related to only one visual word of the codebook, our method utilizes sparse coding to characterize the potential correlation between the descriptor and multiple words. Therefore each descriptor can be represented by a small set of words. Furthermore, in this paper probabilistic Latent Semantic Analysis (pLSA) is applied to learn the latent relation among word, topic and document due to its simplicity and low computational cost. Experimental results on remote sensing image segmentation demonstrate the excellent superiority of our method over k-means clustering and conventional pLSA model.
              </p>
              <pre xml:space="preserve" id="shiIGARSS2013Bib" class="bibtex" style="display: none;">
@inproceedings{shiIGARSS2013, 
  author    = {Jun Shi and Zhiguo Jiang and Hao Feng and Yibing Ma}, 
  booktitle = {2013 IEEE International Geoscience and Remote Sensing Symposium - IGARSS}, 
  title     = {Sparse coding-based topic model for remote sensing image segmentation}, 
  year      = {2013}, 
  pages     = {4122-4125}, 
  doi       = {10.1109/IGARSS.2013.6723740}, 
  ISSN      = {2153-6996}, 
  month     = {July}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('shiIGARSS2013Abs');
                hideblock('shiIGARSS2013Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
        </tbody></table>

        <hr />
        <h3>Before 2013</h3>
        <table><tbody>
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="i" alt="Image" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>SIFT-based Elastic sparse coding for image retrieval</b> <a href="http://ieeexplore.ieee.org/document/6467390" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Jun Shi, Zhiguo Jiang, Hao Feng and Liguo Zhang
                </i></font>
                <br>
                ICIP, 2012
                <br>
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('shiICIP2012Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('shiICIP2012Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="shiICIP2012Abs" class="abstract" style="display: none;">
                Bag-of-features (BoF) model based on SIFT generally assumes each descriptor is related to only one visual word of the codebook. Therefore, the potential correlation between the descriptor and other visual words is ignored. On the other hand, sparse coding through l1-norm regularization fails to generate optimal sparse representations since l1-norm regularization randomly selected one variable from a group of highly correlated variables. In this study we propose a novel bag-of-features model for image retrieval called SIFT-based Elastic sparse coding. The method utilizes a large number of SIFT descriptors to construct the codebook. The Elastic Net regression framework, which combines both l1-norm and l2-norm penalties, is then used to obtain the sparse-coefficient vector corresponding to the SIFT descriptor. Finally each image can be represented by a unified sparse-coefficient vector. Experimental results on Coil20 dataset demonstrate the consistent superiority of the proposed method over the state-of-the-art algorithms including original SIFT matching, conventional BoF strategy and BoF model based on l1-norm sparse coding.
              </p>
              <pre xml:space="preserve" id="shiICIP2012Bib" class="bibtex" style="display: none;">
@inproceedings{shi2012ICIP, 
  author    = {Jun Shi and Zhiguo Jiang and Hao Feng and Liguo Zhang}, 
  booktitle = {2012 19th IEEE International Conference on Image Processing}, 
  title     = {SIFT-based Elastic sparse coding for image retrieval}, 
  year      = {2012},
  pages     = {2437-2440}, 
  doi       = {10.1109/ICIP.2012.6467390}, 
  ISSN      = {1522-4880}, 
  month     = {Sep}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('shiICIP2012Abs');
                hideblock('shiICIP2012Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
        </tbody></table>
      </div>
      </div>
      </article>
      </div>
      </div>
    </section>
    </div><!-- /.container -->

    <footer class="footer">
      <div class="footer-bottom">
        <i class="fa fa-copyright"></i> Copyright 2018. All rights reserved.<br>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript
      ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="scripts/jquery.min.js"></script>
    <script src="scripts/bootstrap.min.js"></script>
    <script src="scripts/jquery.bxslider.js"></script>
    <script src="scripts/mooz.scripts.min.js"></script>
    <script src="scripts/togglehide.js"></script>
  </body>
</html>
