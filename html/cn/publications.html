<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="发表著作">
    <meta name="author" content="WeiQM">
    <link rel="icon" href="../../images/logo/RMX_16.ico">
    <title>REMEX - 发表著作</title>
    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="../../style/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <!-- Custom styles for this template -->
    <link href="../../style/jquery.bxslider.css" rel="stylesheet">
    <link href="../../style/style.css" rel="stylesheet">

  </head>
  <body>
    <!-- Navigation -->
    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          </button>
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li><a href="index.html"><i class="fa fa-home"></i> 主页</a></li>
            <li><a href="people.html">团队成员</a></li>
            <li><a href="research.html">研究项目</a></li>
            <li class="active"><a href="publications.html">发表著作</a></li>
            <li><a href="downloads.html">下载专区</a></li>
            <li><a href="contact.html">联系我们</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <li><a href="../../publications.html">English</a></li>
            <li class="active"><a href="publications.html">中文</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <li><a href="index.html"><img src="../../images/logo/logo_w.png" alt="Logo" width="80px"/></a></li>
          </ul>
        </div>
      </div>
    </nav>

    <div class="container">
    <header>
      <!--
      <a href="index.html"><img src="images/logo.png"  width="256px"></a>
      -->
    </header>

    <!--
    <section class="main-slider">
      <ul class="bxslider">
        <li><div class="slider-item"><img src="images/logo/logo_c.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_m.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_y.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_k.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_r.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_g.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_b.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
      </ul>
    </section>
    -->

    <section>
      <div class="row">
      <div class="col-md-12">
      <article class="content-block">
      <div class="block-body">
      <div class="block-text">


        <!-- -------------------------------------------- -->
        <!-- -------------------------------------------- -->
        <h3>2018</h3>
        <table><tbody>
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_zheng_tmi_2018.jpg" alt="Flowchart" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Histopathological Whole Slide Image Analysis Using Context-based CBIR</b> <a href="http://ieeexplore.ieee.org/document/8265156/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yushan Zheng, Zhiguo Jiang, Haopeng Zhang, Fengying Xie, Yibing Ma, Huaqiang Shi and Yu Zhao
                </i></font>
                <br>
                 TMI, 2018
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="../../source/pdf/article_zheng_tmi_2018.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhengTMI2018Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhengTMI2018Bib')">BibTeX</a> &nbsp;
                <i class="fa fa-link"></i> <a href="../../source/pdf/article_zheng_tmi_2018_sup.pdf" target="_blank">Supplementary</a> &nbsp;
              </p>
              <p id="zhengTMI2018Abs" class="abstract" style="display: none;">
                  Histopathological image classification (HIC) and content-based histopathological image retrieval (CBHIR) are two promising applications for histopathological whole slide image (WSI) analysis. HIC can efficiently predict the type of lesion involved in a histopathological image. In general, HIC can aid pathologists in locating high-risk cancer regions from a WSI by providing a cancerous probability map for the WSI. In contrast, CBHIR was developed to allow searches for regions with similar content for a region of interest (ROI) from a database consisting of historical cases. Sets of cases with similar content are accessible to pathologists, which can provide more valuable references for diagnosis. A drawback of the recent CBHIR framework is that a query ROI needs to be manually selected from a WSI. An automatic CBHIR approach for a WSI-wise analysis needs to be developed. In this paper, we propose a novel aided-diagnosis framework of breast cancer using whole slide images, which shares the advantages of both HIC and CBHIR. In our framework, CBHIR is automatically processed throughout the WSI, based on which a probability map regarding the malignancy of breast tumors is calculated. Through the probability map, the malignant regions in WSIs can be easily recognized. Furthermore, the retrieval results corresponding to each sub-region of the WSIs are recorded during the automatic analysis and are available to pathologists during their diagnosis. Our method was validated on fully annotated WSI datasets of breast tumors. The experimental results certify the effectiveness of the proposed method.
              </p>
              <pre xml:space="preserve" id="zhengTMI2018Bib" class="bibtex" style="display: none;">
@article{zheng2018TMI,
  author  = {Yushan Zheng and Zhiguo Jiang and Haopeng Zhang and Fengying Xie
             and Yibing Ma and Huaqiang Shi and Yu Zhao},
  title   = {Histopathological Whole Slide Image Analysis Using Context-based CBIR},
  journal = {IEEE Transactions on Medical Imaging},
  doi     = {10.1109/TMI.2018.2796130},
  year    = {Epub 2018 January 23},
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhengTMI2018Abs');
                hideblock('zhengTMI2018Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_wei_sensors_2018.jpg" alt="Results of article_wei_sensors_18" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Robust Spacecraft Component Detection in Point Clouds</b> <a href="http://www.mdpi.com/1424-8220/18/4/933" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  <a href="https://weiquanmao.github.io" target="_blank">Quanmao Wei</a>, Zhiguo Jiang and Haopeng Zhang
                </i></font>
                <br>
                Sensors, 2018
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="http://www.mdpi.com/1424-8220/18/4/933/pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('weiSensors18Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('weiSensors18Bib')">BibTeX</a> &nbsp;
                <i class="fa fa-link"></i> <a href="http://www.mdpi.com/1424-8220/18/4/933/s1" target="_blank">Supplementary</a> &nbsp;
              </p>
              <p id="weiSensors18Abs" class="abstract" style="display: none;">
                Automatic component detection of spacecraft can assist in on-orbit operation and space situational awareness. Spacecraft are generally composed of solar panels and cuboidal or cylindrical modules. These components can be simply represented by geometric primitives like plane, cuboid and cylinder. Based on this prior, we propose a robust automatic detection scheme to automatically detect such basic components of spacecraft in three-dimensional (3D) point clouds. In the proposed scheme, cylinders are first detected in the iteration of the energy-based geometric model fitting and cylinder parameter estimation. Then, planes are detected by Hough transform and further described as bounded patches with their minimum bounding rectangles. Finally, the cuboids are detected with pair-wise geometry relations from the detected patches. After successive detection of cylinders, planar patches and cuboids, a mid-level geometry representation of the spacecraft can be delivered. We tested the proposed component detection scheme on spacecraft 3D point clouds synthesized by computer-aided design (CAD) models and those recovered by image-based reconstruction, respectively. Experimental results illustrate that the proposed scheme can detect the basic geometric components effectively and has fine robustness against noise and point distribution density.
              </p>
              <pre xml:space="preserve" id="weiSensors18Bib" class="bibtex" style="display: none;">
@article{weiSensors18,
  author  = {Quanmao Wei and Zhiguo Jiang and Haopeng Zhang},
  title   = {Robust Spacecraft Component Detection in Point Clouds},
  journal = {Sensors},
  volume  = {18},
  year    = {2018},
  number  = {4},
  article number = {933},
  url     = {http://www.mdpi.com/1424-8220/18/4/933},
  issn    = {1424-8220},
  doi     = {10.3390/s18040933}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('weiSensors18Abs');
                hideblock('weiSensors18Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_zhang_taes_2018.jpg" alt="Results of article_zhang_taes_18" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Vision-based Pose Estimation for Textureless Space Objects by Contour Points Matching</b> <a href="http://ieeexplore.ieee.org/document/8315479/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Xin Zhang, Zhiguo Jiang, Haopeng Zhang and <a href="https://weiquanmao.github.io" target="_blank">Quanmao Wei</a>
                </i></font>
                <br>
                TAES, 2018
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8315479" target="_blank">Preprint</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhangTAES18Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhangTAES18Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhangTAES18Abs" class="abstract" style="display: none;">
                This paper presents a novel vision-based method to solve the 6-degree-of-freedom pose estimation problem of textureless space objects from a single monocular image. Our approach follows a coarse-to-fine procedure, utilizing only shape and contour information of the input image. To achieve invariance to initialization, we select a series of projection images which are similar to the input image and establish many-to-one 2D-3D correspondences by contour feature matching. Intensive attention is focused on outlier rejection and we introduce an innovative strategy to fully utilize geometric matching information to guide pose calculation. Experiments based on simulated images are carried out, and the results manifest that pose estimation error of our approach is about 1% even in situations with heavy outlier correspondences.
              </p>
              <pre xml:space="preserve" id="zhangTAES18Bib" class="bibtex" style="display: none;">
@article{zhangTAES18,
  author  = {Xin Zhang and Zhiguo Jiang and Haopeng Zhang and Quanmao Wei},
  journal = {IEEE Transactions on Aerospace and Electronic Systems},
  title   = {Vision-based Pose Estimation for Textureless Space Objects
             by Contour Points Matching},
  year    = {2018},
  month   = {},
  volume  = {PP},
  number  = {99},
  pages   = {1--1},
  issn    = {0018-9251},
  doi     = {10.1109/TAES.2018.2815879}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhangTAES18Abs');
                hideblock('zhangTAES18Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
        </tbody></table>

        <hr />
        <!-- -------------------------------------------- -->
        <!-- -------------------------------------------- -->
        <h3>2017</h3>
        <table><tbody>
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_zheng_pr_2017.jpg" alt="Flowchart_of_N_CNN" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Feature Extraction from Histopathological Images Based on Nucleus-guided Convolutional Neural Network for Breast Lesion Classification</b> <a href="https://www.sciencedirect.com/science/article/pii/S0031320317302005?via%3Dihub" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yushan Zheng, Zhiguo Jiang, Fengying Xie, Haopeng Zhang, Yibing Ma, Huaqiang Shi and Yu Zhao
                </i></font>
                <br>
                PR, 2017
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="../../source/pdf/article_zheng_pr_2017.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhengPR2017Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhengPR2017Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhengPR2017Abs" class="abstract" style="display: none;">
                  Feature extraction is a crucial and challenging aspect in the computer-aided diagnosis of breast cancer with histopathological images. In recent years, many machine learning methods have been introduced to extract features from histopathological images. In this study, a novel nucleus-guided feature extraction framework based on convolutional neural network is proposed for histopathological images. The nuclei are first detected from images, and then used to train a designed convolutional neural network with three hierarchy structures. Through the trained network, image-level features including the pattern and spatial distribution of the nuclei are extracted. The proposed features are evaluated through the classification experiment on a histopathological image database of breast lesions. The experimental results show that the extracted features effectively represent histopathological images, and the proposed framework achieves a better classification performance for breast lesions than the compared state-of-the-art methods.
              </p>
              <pre xml:space="preserve" id="zhengPR2017Bib" class="bibtex" style="display: none;">
@article{zheng2017PR,
  author  = {Yushan Zheng and Zhiguo Jiang and Fengying Xie and Haopeng Zhang
             and Yibing Ma and Huaqiang Shi and Yu Zhao},
  title   = {Feature Extraction from Histopathological Images Based on Nucleus-guided
             Convolutional Neural Network for Breast Lesion Classification},
  journal = {Pattern Recognition},
  year    = {2017},
  volume  = {71},
  pages   = {14—-25},
  issn    = {0031-3203},
  doi     = {10.1016/j.patcog.2017.05.010}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhengPR2017Abs');
                hideblock('zhengPR2017Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_zheng_jbhi_2017.jpg" alt="Flowchart" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Size-scalable Content-based Histopathological Image Retrieval from Database that Consists of WSIs</b> <a href="http://ieeexplore.ieee.org/document/7967806/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yushan Zheng, Zhiguo Jiang, Haopeng Zhang, Fengying Xie, Yibing Ma, Huaqiang Shi and Yu Zhao
                </i></font>
                <br>
                JBHI, 2017
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="../../source/pdf/article_zheng_jbhi_2017.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhengJBHI2017Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhengJBHI2017Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhengJBHI2017Abs" class="abstract" style="display: none;">
                Content-based image retrieval (CBIR) has been widely researched for histopathological images. It is challenging to retrieve contently similar regions from histopathological whole slide images (WSIs) for regions of interest (ROIs) in different size. In this paper, we propose a novel CBIR framework for database that consists of WSIs and size-scalable query ROIs. Each WSI in the database is encoded into a matrix of binary codes. When retrieving, a group of region proposals that have similar size with the query ROI are firstly located in the database through an efficient table-lookup approach. Then, these regions are ranked by a designed multi-binary-code-based similarity measurement. Finally, the top relevant regions and their locations in the WSIs as well as the corresponding diagnostic information are returned to assist pathologists. The effectiveness of the proposed framework is evaluated on a fine-annotated WSI database of epithelial breast tumors. The experimental results have proved that the proposed framework is effective for retrieval from database that consists of WSIs. Specifically, for query ROIs of 4096$\times$4096 pixels, the retrieval precision of the top 20 return has reached 96\% and the retrieval time is less than 1.5 second.
              </p>
              <pre xml:space="preserve" id="zhengJBHI2017Bib" class="bibtex" style="display: none;">
@article{zheng2017JBHI,
  author  = {Yushan Zheng and Zhiguo Jiang Haopeng Zhang and Fengying Xie
             and Yibing Ma and Huaqiang Shi and Yu Zhao},
  title   = {Size-scalable Content-based Histopathological Image Retrieval
             from Database that Consists of WSIs},
  journal = {IEEE journal of biomedical and health informatics},
  doi     = {10.1109/jbhi.2017.2723014},
  year    = {2017}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhengPR2017Abs');
                hideblock('zhengPR2017Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_zhang_sensors_2017.jpg" alt="Results of article_zhang_sensors_17" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>3D Reconstruction of Space Objects from Multi-Views by A Visible Sensor</b> <a href="http://www.mdpi.com/1424-8220/17/7/1689" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Haopeng Zhang, <a href="https://weiquanmao.github.io" target="_blank">Quanmao Wei</a> and Zhiguo Jiang
                </i></font>
                <br>
                Sensors, 2017
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="http://www.mdpi.com/1424-8220/17/7/1689/pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhangSensors17Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhangSensors17Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhangSensors17Abs" class="abstract" style="display: none;">
                In this paper, a novel 3D reconstruction framework is proposed to recover the 3D structural model of a space object from its multi-view images captured by a visible sensor. Given an image sequence, this framework first estimates the relative camera poses and recovers the depths of the surface points by the structure from motion (SFM) method, then the patch-based multi-view stereo (PMVS) algorithm is utilized to generate a dense 3D point cloud. To resolve the wrong matches arising from the symmetric structure and repeated textures of space objects, a new strategy is introduced, in which images are added to SFM in imaging order. Meanwhile, a refining process exploiting the structural prior knowledge that most sub-components of artificial space objects are composed of basic geometric shapes is proposed and applied to the recovered point cloud. The proposed reconstruction framework is tested on both simulated image datasets and real image datasets. Experimental results illustrate that the recovered point cloud models of space objects are accurate and have a complete coverage of the surface. Moreover, outliers and points with severe noise are effectively filtered out by the refinement, resulting in an distinct improvement of the structure and visualization of the recovered points.
              </p>
              <pre xml:space="preserve" id="zhangSensors17Bib" class="bibtex" style="display: none;">
@article{zhangSensors17,
  author  = {Haopeng Zhang and Quanmao Wei and Zhiguo Jiang},
  title   = {3D Reconstruction of Space Objects from Multi-Views by A Visible Sensor},
  journal = {Sensors},
  volume  = {17},
  year    = {2017},
  number  = {7},
  article number = {1689},
  url     = {http://www.mdpi.com/1424-8220/17/7/1689},
  issn    = {1424-8220},
  doi     = {10.3390/s17071689}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhangSensors17Abs');
                hideblock('zhangSensors17Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_wei_igta_2017.jpg" alt="Results of article_wei_igta_17" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Spacecraft component detection in point clouds</b> <a href="https://link.springer.com/chapter/10.1007/978-981-10-7389-2_21" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  <a href="https://weiquanmao.github.io" target="_blank">Quanmao Wei</a>, Zhiguo Jiang, Haopeng Zhang and Nie Shanlan
                </i></font>
                <br>
                IGTA, 2017
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="https://link.springer.com/content/pdf/10.1007%2F978-981-10-7389-2_21.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('weiIGTA17Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('weiIGTA17Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="weiIGTA17Abs" class="abstract" style="display: none;">
                Component detection of spacecraft is significant for on-orbit operation and space situational awareness. Solar wings and main body are the major components of most spacecrafts, and can be described by geometric primitives like planes, cuboid or cylinder. Based on this prior, pipeline to automatically detect the basic components of spacecraft in 3D point clouds is presented, in which planes, cuboid and cylinder are successively detected. The planar patches are first detected as possible solar wings in point clouds of the recorded object. As for detection of the main body, inferring a cuboid main body from the detected patches is first attempted, and a further attempt to extract a cylinder main body is made if no cuboid exists. Dimensions are estimated for each component. Experiments on satellite point cloud data that are recovered by image-based reconstruction demonstrated effectiveness and accuracy of this pipeline.
              </p>
              <pre xml:space="preserve" id="weiIGTA17Bib" class="bibtex" style="display: none;">
@inproceedings{weiIGTA17,
  author    = {Quanmao Wei and Zhiguo Jiang and Haopeng Zhang and Shanlan Nie},
  editor    = {Yongtian Wang and Shengjin Wang and Yue Liu and Jian Yang
               and Xiaoru Yuan and Ran He and Henry Been-Lirn Duh},
  title     = {Spacecraft Component Detection in Point Clouds},
  booktitle = {Advances in Image and Graphics Technologies},
  year      = {2017},
  publisher = {Springer Singapore},
  address   = {Singapore},
  pages     = {210--218},
  isbn      = {978-981-10-7389-2}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('weiIGTA17Abs');
                hideblock('weiIGTA17Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_cai_rs_2017.jpg" alt="flowchart_of_cai_rs_17" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Airport Detection Using End-to-End Convolutional Neural Network with Hard Example Mining</b> <a href="http://www.mdpi.com/2072-4292/9/11/1198" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Bowen Cai, Zhiguo Jiang, Haopeng Zhang, Danpei Zhao and Yuan Yao
                </i></font>
                <br>
                remote sensing, 2017
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="http://www.mdpi.com/2072-4292/9/11/1198/pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('caiRS2017Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('caiRS2017Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="caiRS2017Abs" class="abstract" style="display: none;">
                  Deep convolutional neural network (CNN) achieves outstanding performance in the field of target detection. As one of the most typical targets in remote sensing images (RSIs), airport has attracted increasing attention in recent years. However, the essential challenge for using deep CNN to detect airport is the great imbalance between the number of airports and background examples in large-scale RSIs, which may lead to over-fitting. In this paper, we develop a hard example mining and weight-balanced strategy to construct a novel end-to-end convolutional neural network for airport detection. The initial motivation of the proposed method is that backgrounds contain an overwhelming number of easy examples and a few hard examples. Therefore, we design a hard example mining layer to automatically select hard examples by their losses, and implement a new weight-balanced loss function to optimize CNN. Meanwhile, the cascade design of proposal extraction and object detection in our network releases the constraint on input image size and reduces spurious false positives. Compared with geometric characteristics and low-level manually designed features, the hard example mining based network could extract high-level features, which is more robust for airport detection in complex environment. The proposed method is validated on a multi-scale dataset with complex background collected from Google Earth. The experimental results demonstrate that our proposed method is robust, and superior to the state-of-the-art airport detection models.
              </p>
              <pre xml:space="preserve" id="caiRS2017Bib" class="bibtex" style="display: none;">
@article{caiRS17,
  author  = {Bowen Cai and Zhiguo Jiang and Haopeng Zhang and Danpei Zhao and Yuan Yao},
  title   = {Airport Detection Using End-to-End Convolutional Neural Network
             with Hard Example Mining},
  journal = {Remote Sensing},
  volume  = {9},
  year    = {2017},
  number  = {11},
  article number = {1198},
  url     = {http://www.mdpi.com/2072-4292/9/11/1198},
  issn    = {2072-4292},
  doi     = {10.3390/rs9111198}
}}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('caiRS2017Abs');
                hideblock('caiRS2017Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_cai_igarss_2017.jpg" alt="flowchart_of_cai_igarss_17" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Training Deep Convolution Neural Network with Hard Example Mining for Airport Detection</b> <a href="http://ieeexplore.ieee.org/document/8127089/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Bowen Cai, Zhiguo Jiang, Haopeng Zhang, Yuan Yao and Jie Huang
                </i></font>
                <br>
                IGARSS, 2017
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8127089" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('caiIGARSS2017Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('caiIGARSS2017Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="caiIGARSS2017Abs" class="abstract" style="display: none;">
                  The geometrical characteristic and low-level manually designed features are usually used to detect airports in optical remote sensing images. But it is insufficient to describe airport in low resolution and illumination environment. This paper presents a hard example mining algorithm to train the end-to-end deep convolutional neural network for airport detection in complex situation. Compared with conventional airport detection methods which design specific low-level manually designed features for high-resolution remote sensing images, an end-to-end network can mine the general characteristic among the training samples and learn high-level features in multi-scale and multi-view remote sensing images. Meanwhile, an automatic hard example mining principle is introduced to make training more efficiently and accurately. The proposed method is validated on a multi-scale and multi-view dataset collected from Google Earth. The experimental results demonstrate that the proposed method is robust and efficient, and superior to the state-of-the-art airport detection models.
              </p>
              <pre xml:space="preserve" id="caiIGARSS2017Bib" class="bibtex" style="display: none;">
@inproceedings{caiIGARSS17,
  author    = {Bowen Cai and Zhiguo Jiang and Haopeng Zhang and Yuan Yao and Jie Huang},
  booktitle = {2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
  title     = {Training Deep Donvolution Neural Network
               with Hard Example Mining for Airport Detection},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {862—-865},
  doi       = {10.1109/IGARSS.2017.8127089},
  issn      = {},
  month     = {July}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('caiIGARSS2017Abs');
                hideblock('caiIGARSS2017Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_zheng_spiemi_2017.jpg" alt="Flowchart" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Content-based Histopathological Image Retrieval for Whole Slide Image Database Using Binary Codes</b> <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10140/1/Content-based-histopathological-image-retrieval-for-whole-slide-image-database/10.1117/12.2253988.full?SSO=1" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yushan Zheng, Zhiguo Jiang, Yibing Ma, Haopeng Zhang, Fengying Xie, Huaqiang Shi and Yu Zhao
                </i></font>
                <br>
                SPIE MI, 2017
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="../../source/pdf/article_zheng_spiemi_2017.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhengSPIEMI2017Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhengSPIEMI2017Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhengSPIEMI2017Abs" class="abstract" style="display: none;">
                Content-based image retrieval (CBIR) has been widely researched for medical images. In application of histo- pathological images, there are two issues that need to be carefully considered. The one is that the digital slide is stored in a spatially continuous image with a size of more than 10K x 10K pixels. The other is that the size of query image varies in a large range according to different diagnostic conditions. It is a challenging work to retrieve the eligible regions for the query image from the database that consists of whole slide images (WSIs). In this paper, we proposed a CBIR framework for the WSI database and size-scalable query images. Each WSI in the database is encoded and stored in a matrix of binary codes. When retrieving, the query image is first encoded into a set of binary codes and analyzed to pre-choose a set of regions from database using hashing method. Then a multi-binary-code-based similarity measurement based on hamming distance is designed to rank proposal regions. Finally, the top relevant regions and their locations in the WSIs along with the diagnostic information are returned to assist pathologists in diagnoses. The effectiveness of the proposed framework is evaluated in a fine-annotated WSIs database of epithelial breast tumors. The experimental results show that proposed framework is both effective and efficiency for content-based whole slide image retrieval.
              </p>
              <pre xml:space="preserve" id="zhengSPIEMI2017Bib" class="bibtex" style="display: none;">
@inproceedings{zhengSPIEME17,
  title     = {Content-based Histopathological Image Retrieval
               for Whole Slide Image Database Using Binary Codes},
  author    = {Yushan Zheng and Zhiguo Jiang and Yibing Ma and Haopeng Zhang
               and Fengying Xie and Huaqiang Shi and Yu Zhao},
  booktitle = {SPIE Medical Imaging},
  doi       = {doi.org/10.1117/12.2253988},
  pages     = {1014013},
  year      = {2017}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhengSPIEMI2017Abs');
                hideblock('zhengSPIEMI2017Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
        </tbody></table>

        <hr />
        <!-- -------------------------------------------- -->
        <!-- -------------------------------------------- -->
        <h3>2016</h3>
        <table><tbody>
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_zhang_igta_2016.jpg" alt="Results of article_zhang_igta_16" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Pose Estimation of Space Objects Based on Hybrid Feature Matching of Contour Points</b> <a href="https://link.springer.com/chapter/10.1007/978-981-10-2260-9_21" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Xin Zhang, Haopeng Zhang, <a href="https://weiquanmao.github.io" target="_blank">Quanmao Wei</a> and Zhiguo Jiang
                </i></font>
                <br>
                IGTA, 2016
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="https://link.springer.com/content/pdf/10.1007%2F978-981-10-2260-9_21.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhangIGTA16Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhangIGTA16Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhangIGTA16Abs" class="abstract" style="display: none;">
                This paper presents an improved pose estimation algorithm for vision-based space objects. The major weakness of most existing methods is limited convergence radius. In most cases they ignore the influence of translation, only focusing on rotation parameters. To breakthrough these limits, we utilizes hybrid local image features to explicitly establish 2D-3D correspondences between the input image and 3D model of space objects, and then estimate rotation and translation parameters based on the correspondences. Experiments with simulated models are carried out, and the results show that our algorithm can successfully estimate the pose of space objects with large convergence radius and high accuracy.
              </p>
              <pre xml:space="preserve" id="zhangIGTA16Bib" class="bibtex" style="display: none;">
@inproceedings{zhangIGTA16,
  author    = {Xin Zhang and Haopeng Zhang and Quanmao Wei and Zhiguo Jiang},
  editor    = {Tieniu Tan and Guoping Wang and Shengjin Wang and Yue Liu
               and Xiaoru Yuan and Ran He and Sheng Li},
  title     = {Pose Estimation of Space Objects Based on Hybrid Feature Matching
               of Contour Points},
  booktitle = {Advances in Image and Graphics Technologies},
  year      = {2016},
  publisher = {Springer Singapore},
  address   = {Singapore},
  pages     = {184--191},
  isbn      = {978-981-10-2260-9}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhangIGTA16Abs');
                hideblock('zhangIGTA16Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_zhang_jbuaa_2016.jpg" alt="Results of article_zhang_jbuaa_16" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Sequential-image-based Space Object 3D Reconstruction</b> <a href="http://doi.cnki.net/Resolution/Handler?doi=10.13700/j.bh.1001-5965.2015.0117" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Haopeng Zhang, <a href="https://weiquanmao.github.io" target="_blank">Quanmao Wei</a>, Wei Zhang, Junfeng Wu and Zhiguo Jiang
                </i></font>
                <br>
                JBUAA, 2016 <i>[In Chinese]</i>
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="http://bhxb.buaa.edu.cn/CN/article/downloadArticleFile.do?attachType=PDF&id=13381" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhangJBUAA16Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhangJBUAA16Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhangJBUAA16Abs" class="abstract" style="display: none;">
                Space object 3D reconstruction is of important significance for both space situational awareness and theoretical study. A new structure from motion method was proposed to avoid the reconstruction error caused by the symmetrical structure and similar texture of space targets. In this method, new images were added sequentially for reconstruction using the imaging time as a priori knowledge. In addition, image simulation of space target and ground imaging simulation experiment were carried out for the lack of space target image data. And experiments on the simulated space target images, in which the motion analysis results are accurate and robust to noise, and the recovery 3D point cloud can express the structural information of the target to a certain extent, have demonstrated the effectiveness of the approach proposed, and the boundary conditions of multi-frame-image for 3D reconstruction are acquired as well.
              </p>
              <pre xml:space="preserve" id="zhangJBUAA16Bib" class="bibtex" style="display: none;">
@article{zhangJBUAA16,
  language = {Chinse},
  author   = {Haopeng Zhang and Quanmao Wei and Wei Zhang and Junfeng Wu
              and Zhiguo Jiang},
  title    = {Sequential-image-based Space Object 3D Reconstruction},
  journal  = {Journal of Beijing University of Aeronautics and Astronautics},
  year     = {2016},
  volume   = {42},
  number   = {2},
  pages    = {273--279},
  issn     = {10015965},
  URL      = {http://dx.doi.org/10.13700/j.bh.1001-5965.2015.0117}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhangJBUAA16Abs');
                hideblock('zhangJBUAA16Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_yao_igarss_2016.jpg" alt="Results of article_yao_igarss_2016" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>High-resolution Optical Satellite Image Simulation of Ship Target in Large Sea Scenes</b> <a href="http://ieeexplore.ieee.org/document/7729314/" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yuan Yao, Zhiguo Jiang and Haopeng Zhang
                </i></font>
                <br>
                IGRASS, 2016
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="../../source/pdf/article_yao_igarss_2016.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('yaoIGARSS16Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('yaoIGARSS16Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="yaoIGARSS16Abs" class="abstract" style="display: none;">
                Ship target detection in optical remote sensing images has attracted more and more attention in the field of remote sensing. The ship target detection technology of optical remote sensing images is vulnerable to many factors, while the real data are difficult to contain various elements. In order to obtain the various situations in the large sea scenes, we develop a simulation system for high-resolution optical remote sensing image of ship targets. The simulated images with different sea states, cloud conditions, target types and imaging conditions can support the evaluation and comparison of ship detection algorithms as well as other tasks in remote sensing image analysis.
              </p>
              <pre xml:space="preserve" id="yaoIGARSS16Bib" class="bibtex" style="display: none;">
@inproceedings{yaoIGARSS16,
  author    = {Yuan Yao and Zhiguo Jiang and Haopeng Zhang},
  booktitle = {2016 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
  title     = {High-resolution Optical Satellite Image Simulation of Ship Target
               in Large Sea Scenes},
  year      = {2016},
  month     = {July},
  volume    = {},
  number    = {},
  pages     = {1241—-1244},
  doi       = {10.1109/IGARSS.2016.7729314}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('yaoIGARSS16Abs');
                hideblock('yaoIGARSS16Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
        </tbody></table>

        <hr />
        <!-- -------------------------------------------- -->
        <!-- -------------------------------------------- -->
        <h3>2015</h3>
        <table><tbody>

        </tbody></table>

        <hr />
        <!-- -------------------------------------------- -->
        <!-- -------------------------------------------- -->
        <h3>2014</h3>
        <table><tbody>
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_zheng_icip_2014.jpg" alt="Flowchart" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Retrieval of Pathology Image for Breast Cancer Using PLSA Model Based on Texture and Pahological Features</b> <a href="http://xueshu.baidu.com/s?wd=paperuri%3A%280ffc62d136826578e27817d048608818%29&filter=sc_long_sign&tn=SE_xueshusource_2kduw22v&sc_vurl=http%3A%2F%2Fdx.doi.org%2F10.1109%2Ficip.2014.7025467&ie=utf-8&sc_us=1281695813514094042" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yushan Zheng, Zhiguo Jiang, Jun Shi and Yibing Ma
                </i></font>
                <br>
                ICIP, 2014
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="../../source/pdf/article_zheng_icip_2014.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhengICIP2014Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhengICIP2014Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhengICIP2014Abs" class="abstract" style="display: none;">
                Content-based image retrieval (CBIR) for digital pathology slides is of clinical use for breast cancer aided diagnosis. One of the largest challenges in CBIR is feature extraction. In this paper, we propose a novel pathology image retrieval method for breast cancer, which aims to characterize the pathology image content through texture and pathological features and further discover the latent high-level semantics. Specifically, the proposed method utilizes block Gabor features to describe the texture structure, and simultaneously designs nucleus-based pathological features to describe morphological characteristics of nuclei. Based on these two kinds of local feature descriptors, two codebooks are built to learn the probabilistic latent semantic analysis (pLSA) models. Consequently, each image is represented by the topics of pLSA models which can reveal the semantic concepts. Experimental results on the digital pathology image database for breast cancer demonstrate the feasibility and effectiveness of our method.
              </p>
              <pre xml:space="preserve" id="zhengICIP2014Bib" class="bibtex" style="display: none;">
@article{zhengICIP14,
  title     = {Retrieval of Pathology Image for Breast Cancer Using PLSA Model
               Based on Texture and Pahological Features},
  author    = {Yushan Zheng and Zhiguo Jiang and Jun Shi and Yibing Ma},
  booktitle = {2016 IEEE International Conference on Image Processing (ICIP)},
  pages     = {2304--2308},
  year      = {2014}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhengICIP2014Abs');
                hideblock('zhengICIP2014Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->
          <tr> <!-- An Paper -->
            <td width="22%" valign="top"><p>
              <img src="../../images/src/article_zheng_igta_2014.jpg" alt="Flowchart" width="200">
            </p></td>
            <td width="78%" valign="top">
              <p>
                <b>Pathology Image Retrieval by Block LBP Based PLSA Model with Low-Rank and Sparse Matrix Decomposition</b> <a href="https://link.springer.com/chapter/10.1007/978-3-662-45498-5_36" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                  Yushan Zheng, Zhiguo Jiang, Jun Shi and Yibing Ma
                </i></font>
                <br>
                IGTA, 2014
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="../../source/pdf/article_zheng_igta_2014.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhengIGTA2014Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhengIGTA2014Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="zhengIGTA2014Abs" class="abstract" style="display: none;">
                Content-based image retrieval (CBIR) is widely used in Computer Aided Diagnosis (CAD) systems which can aid pathologist to make reasonable decision by querying the slides with diagnostic information from the digital pathology slide database. In this paper, we propose a novel pathology image retrieval method for breast cancer. It firstly applies block Local Binary Pattern (LBP) features to describe the spatial texture property of pathology image, and then use them to construct the probabilistic latent semantic analysis (pLSA) model which generally takes advantage of visual words to mine the topic-level representation of image and thus reveals the high-level semantics. Different from conventional pLSA model, we employ low-rank and sparse matrix composition for describing the correlated and specific characteristics of visual words. Therefore, the more discriminative topic-level representation corresponding to each pathology image can be obtained. Experimental results on the digital pathology image database for breast cancer demonstrate the feasibility and effectiveness of our method.
              </p>
              <pre xml:space="preserve" id="zhengIGTA2014Bib" class="bibtex" style="display: none;">
@inproceedings{zhengIGTA14,
  title     = {Pathology Image Retrieval by Block LBP Based PLSA Model
               with Low-Rank and Sparse Matrix Decomposition},
  author    = {Yushan Zheng and Zhiguo Jiang and Jun Shi and Yibing Ma},
  booktitle = {Advances in Image and Graphics Technologies},
  pages     = {327—-335},
  year      = {2014}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhengIGTA2014Abs');
                hideblock('zhengIGTA2014Bib');
              </script>
            </td>
          </tr> <!-- Paper End Here -->


        </tbody></table>

        <hr />
        <!-- -------------------------------------------- -->
        <!-- -------------------------------------------- -->
        <h3>2013</h3>
        <table><tbody>

        </tbody></table>

        <hr />
        <h3>2013之前</h3>
        <table><tbody>

        </tbody></table>
      </div>
      </div>
      </article>
      </div>
      </div>
    </section>
    </div><!-- /.container -->

    <footer class="footer">
      <div class="footer-bottom">
        <i class="fa fa-copyright"></i> Copyright 2018. All rights reserved.<br>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript
      ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../../scripts/jquery.min.js"></script>
    <script src="../../scripts/bootstrap.min.js"></script>
    <script src="../../scripts/jquery.bxslider.js"></script>
    <script src="../../scripts/mooz.scripts.min.js"></script>
    <script src="../../scripts/togglehide.js"></script>
  </body>
</html>
