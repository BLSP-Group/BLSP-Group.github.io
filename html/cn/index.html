<!DOCTYPE html>
<html lang="zh-CN">

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="REMEX主页">
    <meta name="author" content="WeiQM">
    <link rel="icon" href="../../images/logo/RMX_16.ico">
    <title>REMEX - Remote sensing + Medical imaging + X-features</title>
    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="../../style/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <!-- Custom styles for this template -->
    <link href="../../style/jquery.bxslider.css" rel="stylesheet">
    <link href="../../style/style.css" rel="stylesheet">
  </head>

  <body>
    <!-- Navigation -->
    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          </button>
        </div>
        <div id="navbar" class="collapse navbar-collapse">  
          <ul class="nav navbar-nav">
            <li class="active"><a href="index.html"><i class="fa fa-home"></i> 主页</a></li>
            <li><a href="people.html">团队成员</a></li>
            <li><a href="research.html">研究项目</a></li>
            <li><a href="publications.html">发表著作</a></li>
            <li><a href="downloads.html">下载专区</a></li>
            <li><a href="contact.html">联系我们</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <li><a href="../../index.html">English</a></li>
            <li class="active"><a href="index.html">中文</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <li><a href="index.html"><img src="../../images/logo/logo_w.png" alt="Logo" width="80px"/></a></li>
          </ul>
        </div>
      </div>
    </nav>
    <div class="container">
    <header>
      <!--
      <a href="index.html"><img src="images/logo.png"  width="256px"></a>
      -->
    </header>
    <!--
    <section class="main-slider">
      <ul class="bxslider">
        <li><div class="slider-item"><img src="images/logo/logo_c.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_m.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_y.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_k.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_r.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_g.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_b.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
      </ul>
    </section>
    -->
    <section>
      <div class="row">
        <!-- Main Page -->
        <div class="col-md-8">
          <introduce class="content-block">
            <div class="block-body">
              <img src="../../images/logo.png" alt="Logo" width="512px">
              <p><br>
                <b>REMEX</b> (<b>Re</b>mote sensing and <b>Me</b>dical imaging with <b>X</b>-features) 
                实验室由姜志国教授负责，团队成员包括谢凤英教授、赵丹培副教授、张浩鹏副教授、郑钰山副教授。
                主要研究方向包括图像处理、模式识别、深度学习等人工智能技术及其在航天遥感、医学图像等领域的应用。
                实验室依托“数字媒体”北京市重点实验室、北京市生物医学工程高精尖创新中心和“航天器设计优化与动态模拟技术”教育部重点实验室三个省部级科研平台，
                在遥感图像处理和分析、空间目标图像处理、医学成像分析等方向承担多项国家自然科学基金、国家重点研发计划、国防预研、973、863、高分辨率对地观测重大专项等国家级科研项目。
                实验室隶属北航宇航学院，招收“模式识别与智能系统（控制科学与工程）”和“电子信息”两个学科的学术和专业学位硕博士研究生。
              </p>
              
              <div class="block-image">
                <img src="../../images/photo/Team.jpg" alt="Team photo">
              </div>
              
              <hr/>
              <h3 align="middle"><font color="FF0000">【New】</font>北航REMEX实验室2022年夏令营活动公告</h3>
              <div class="camp-new">
                  &#12288;&#12288;为进一步扩大宣传，增进师生交流，为2022年接收推免生选拔优秀生源并吸引优秀应届本科毕业生报考，特组织本次活动，热忱欢迎全国高校优秀大学生到北航REMEX实验室继续深造！
              </div>
<!--                为进一步扩大宣传，增进师生交流，为2022年接收推免生选拔优秀生源并吸引优秀应届本科毕业生报考，特组织本次活动，热忱欢迎全国高校优秀大学生到北航REMEX实验室继续深造！-->
              <h4 align="left">一、申请资格</h4>
                <div class="camp-new">
                  1. “双一流”、“985”或“211”重点高校信息类及相关专业本科三年级在校生（2023届毕业生），个别有突出成果或特殊专业特长的其他高校本科三年级在校生（2023届毕业生）也可申请。<br \>
                  2. 学习成绩优秀，预计能在就读学校获得推荐免试名额或拟报考北航宇航学院研究生。<br \>
                  3. 对图像处理、模式识别、计算机视觉、机器学习等人工智能相关科学研究有浓厚兴趣，有较强科研潜力。<br \>
                  4. 外语水平良好。<br \>
                  5. 身心健康。   <br \>
                </div>
              <h4 align="left">二、申请材料及提交方式</h4>
                <div class="camp-new">
                    1. 填写报名问卷：<a href="https://www.wjx.cn/vm/ex9mdOo.aspx">https://www.wjx.cn/vm/ex9mdOo.aspx</a>
                    <div class="block-image">
                        <img src="../../images/material/qc.jpg" alt="Team photo">
                    </div>
                    2. 结合本人实际情况，将个人简历、个人陈述、成绩单、相关证明材料（如学习或科研类主要的获奖证书、发表的研究论文首页、英语六级证书等）等合成为一份“姓名+本科学校.pdf”文件，以“夏令营报名+姓名+本科学校”为主题，发送邮件至buaazhp@126.com或其他意向导师邮箱。
                </div>
              <h4 align="left">三、活动内容及时间安排</h4>
                <div class="camp-new">
                    1. 报名截止日期：2022年7月10日（暂定），报名结果单独通知。<br \>
                    2. 线上活动时间：2022年7月中旬（具体时间另行通知）。<br \>
                    3. 活动内容：实验室研究方向介绍、师生交流等。<br \>
                </div>
              <h4 align="left">四、说明</h4>
                <div class="camp-new">
                    1. 本活动非官方活动，为REMEX实验室组织的师生交流活动，仅限意向导师为本实验室成员的学生参加，为加深师生相互了解提供平台。<br \>
                    2. 学生须通过宇航学院研究生推免招生或统考招生方能获得北航录取资格。<br \>
                    3. REMEX实验室主页：<a href="https://remex-lab.github.io/index.html">https://remex-lab.github.io/index.html</a><br \>
                </div>
                
              <hr/>
              <h3 align="left">近期发表</h3><br />
              <div class="block-text">
              <table><tbody>
                
                <tr> <!-- An Paper -->
                  <p>
                      <b>Encoding Histopathology Whole Slide Images with Location-aware Graphs for Diagnostically Relevant Regions Retrieval</b> <a href="https://doi.org/10.1016/j.media.2021.102308" target="_blank"><i class="fa fa-external-link"></i></a>
                      <br>
                      <font size="3pt" face="Georgia"><i>
                          <a href="https://zhengyushan.github.io" target="_blank">Yushan Zheng</a>, Zhiguo Jiang*, Jun Shi, Fengying Xie, <a href="https://haopzhang.github.io" target="_blank">Haopeng Zhang</a>, Wei Luo, Dingyi Hu, Shujiao Sun, Zhongmin Jiang, and Chenghai Xue
                      </i></font>
                      <br>
                      Medical Image Analysis, 2022
                      <br>
                      <i class="fa fa-file-pdf-o"></i> <a href="../../source/pdf/article_zheng_mia_2021.pdf" target="_blank">PDF</a>
                      <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('ZhengMIA2021Abs')">Abstract</a> &nbsp;
                      <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('ZhengMIA2021Bib')">BibTeX</a> &nbsp;
                      <i class="fa fa-github"></i> <a href="https://github.com/Zhengyushan/lagenet" target="_blank">Code</a>
                  </p>
                  <p id="ZhengMIA2021Abs" class="abstract" style="display: none;">
                      Content-based histopathological image retrieval (CBHIR) has become popular in recent years in histopathological image analysis. CBHIR systems provide auxiliary diagnosis information for pathologists by searching for and returning regions that are contently similar to the region of interest (ROI) from a pre-established database. It is challenging and yet significant in clinical applications to retrieve diagnostically relevant regions from a database consisting of histopathological whole slide images (WSIs). In this paper, we propose a novel framework for regions retrieval from WSI database based on location-aware graphs and deep hash techniques. Compared to the present CBHIR framework, both structural information and global location information of ROIs in the WSI are preserved by graph convolution and self-attention operations, which makes the retrieval framework more sensitive to regions that are similar in tissue distribution. Moreover, benefited from the graph structure, the proposed framework has good scalability for both the size and shape variation of ROIs. It allows the pathologist to define query regions using free curves according to the appearance of tissue. Thirdly, the retrieval is achieved based on the hash technique, which ensures the framework is efficient and adequate for practical large-scale WSI database. The proposed method was evaluated on an in-house endometrium dataset with 2650 WSIs and the public ACDC-LungHP dataset. The experimental results have demonstrated that the proposed method achieved a mean average precision above 0.667 on the  endometrium dataset and above 0.869 on the ACDC-LungHP dataset in the task of irregular region retrieval, which are superior to the state-of-the-art methods. The average retrieval time from a database containing 1855 WSIs is 0.752 ms.
                  </p>
                  <pre xml:space="preserve" id="ZhengMIA2021Bib" class="bibtex" style="display: none;">
    @Article{zheng2022encoding,
      author  = {Zheng, Yushan and Jiang, Zhiguo and Shi, Jun and Xie, Fengying and Zhang, Haopeng and
                  Luo, Wei and Hu, Dingyi and Sun, Shujiao and Jiang, Zhongmin and Xue, Chenghai},
      title   = {Encoding histopathology whole slide images with location-aware graphs for diagnostically relevant regions retrieval},
      journal = {Medical Image Analysis},
      year    = {2022},
      volumn  = {76},
      pages   = {102308},
      doi     = {https://doi.org/10.1016/j.media.2021.102308},
    }
                  </pre>
                      <script language="javascript" type="text/javascript" xml:space="preserve">
                    hideblock('ZhengMIA2021Abs');
                    hideblock('ZhengMIA2021Bib');
                  </script>
                  </td>
              </tr> <!-- Paper End Here -->   
              <tr> <!-- An Paper -->
                <p>
                    <b>Weakly Supervised Histopathological Image Representation Learning based on Contrastive Dynamic Clustering</b> <!--a href="https://doi.org/10.1016/j.media.2021.102308" target="_blank"><i class="fa fa-external-link"></i></a-->
                    <br>
                    <font size="3pt" face="Georgia"><i>
                        Jun Li, Zhiguo Jiang, <a href="https://zhengyushan.github.io" target="_blank">Yushan Zheng*</a>, <a href="https://haopzhang.github.io" target="_blank">Haopeng Zhang</a>, Jun Shi, Dingyi Hu,  Wei Luo, Zhongmin Jiang, and Chenghai Xue
                    </i></font>
                    <br>
                    SPIE Medical Imaging, 2022
                    <br>
                    <i class="fa fa-file-pdf-o"></i> <a href="../../source/pdf/article_li_spiemi_2022.pdf" target="_blank">PDF</a>
                    <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('LiSPIEMI2022Abs')">Abstract</a> &nbsp;
                    <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('LiSPIEMI2022Bib')">BibTeX</a> &nbsp;
                    <i class="fa fa-github"></i> <a href="https://github.com/junl21/cdc" target="_blank">Code</a>
                </p>
                <p id="LiSPIEMI2022Abs" class="abstract" style="display: none;">
                    Feature representations of histopathology whole slide images (WSIs) are crucial to the downstream applications
                    for computer-aided cancer diagnosis, including whole slide image classification, region of interest detection, hash
                    retrieval, prognosis analysis, and other high-level inference tasks. State-of-the-art methods for whole slide image
                    feature extraction generally rely on supervised learning algorithms based on fine-grained manual annotations,
                    unsupervised learning algorithms without annotation, or directly use pre-trained features. At present, there is
                    a lack of research on weakly supervised feature learning methods that only utilize WSI-level labeling. In this
                    paper, we propose a weakly supervised framework that learns the feature representations of various lesion areas
                    from histopathology whole slide images. The proposed framework consists of a contrastive learning network as
                    the backbone and a designed contrastive dynamic clustering (CDC) module to embedding the lesion information
                    into the feature representations. The proposed method was evaluated on a large scale endometrial whole slide
                    image dataset. The experimental results have demonstrated that our method can learn discriminative feature
                    representations for histopathology image classification and the quantitative performance of our method is close
                    to the fully-supervision learning methods
                </p>
                <pre xml:space="preserve" id="LiSPIEMI2022Bib" class="bibtex" style="display: none;">
  @inproceedings{li2021weakly,
    author    = {Jun Li, Zhiguo Jiang, Yushan Zheng, Haopeng Zhang, Jun Shi, Dingyi Hu,
                 Wei Luo, Zhongmin Jiang, and Chenghai Xue},
    title     = {Weakly Supervised Histopathological Image Representation Learning based on Contrastive Dynamic Clustering},
    booktitle = {SPEI Medical Imaging 2022},
    year      = {2022},
  }
                </pre>
                    <script language="javascript" type="text/javascript" xml:space="preserve">
                  hideblock('LiSPIEMI2022Abs');
                  hideblock('LiSPIEMI2022Bib');
                </script>
                </td>
            </tr> <!-- Paper End Here -->

            <tr> <!-- An Paper -->
              <p>
                  <b>Hyperspectral Image Classification using Feature Fusion Hypergraph Convolution Neural Network</b> <a href="https://doi.org/10.1109/TGRS.2021.3123423" target="_blank"><i class="fa fa-external-link"></i></a>
                  <br>
                  <font size="3pt" face="Georgia"><i>
                      Zhongtian Ma, Zhiguo Jiang, <a href="https://haopzhang.github.io" target="_blank">Haopeng Zhang</a>
                  </i></font>
                  <br>
                  IEEE Transactions on Geoscience and Remote Sensing, 2021
                  <br>
                  <i class="fa fa-file-pdf-o"></i> <a href="../../source/pdf/article_ma_tgrs_2021.pdf" target="_blank">PDF</a>
                  <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('MaTGRS2021Abs')">Abstract</a> &nbsp;
                  <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('MaTGRS2021Bib')">BibTeX</a> &nbsp;
              </p>
              <p id="MaTGRS2021Abs" class="abstract" style="display: none;">
                  Convolutional neural networks (CNN) and graph representation learning are two common methods for hyperspectral image (HSI) classification. Recently, graph convolutional neural networks (GCN), a combination of CNN and graph representation learning, have shown great potential in HSI classification problem. However, the existing GCN-based methods have many problems, such as over dependence on the adjacency matrix, usage of a single modal feature, and lower accuracy than the mature CNN method. In this paper, we propose a feature fusion hypergraph convolutional neural network (F2HNN) for HSI classification. F2HNN first generates hyperedges from features of different modalities to construct a hypergraph representing multi-modal features in HSI. Then, the HSI and the extracted hypergraph are input into the hypergraph convolutional neural network for learning. In addition, we proposes three feature fusion strategies. The first strategy is the most basic spatial and spectral feature fusion. The second strategy fuses the spectral features extracted by a pre-trained multilayer perceptron (MLP) with the spatial features to reduce the redundant information of the original spectral features. The third strategy uses the fusion of CNN features, spectral features and spatial features to explore the capabilities of F2HNN. Sufficient experiments on four datasets have proved the effectiveness of F2HNN.
              </p>
              <pre xml:space="preserve" id="MaTGRS2021Bib" class="bibtex" style="display: none;">
@ARTICLE{9590574,
  author={Ma, Zhongtian and Jiang, Zhiguo and Zhang, Haopeng},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  title={Hyperspectral Image Classification using Feature Fusion Hypergraph Convolution Neural Network},
  year={2021},
  volume={},
  number={},
  pages={1-1},
  doi={10.1109/TGRS.2021.3123423}
}

              </pre>
                  <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('MaTGRS2021Abs');
                hideblock('MaTGRS2021Bib');
              </script>
              </td>
          </tr> <!-- Paper End Here -->

          <tr> <!-- An Paper -->
            <p>
                <b>Self-Attention Fusion Module for Single Remote Sensing Image Super-Resolution</b> <a href="https://doi.org/10.1109/IGARSS47720.2021.9553766" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                    Han Mei, <a href="https://haopzhang.github.io" target="_blank">Haopeng Zhang</a>, Zhiguo Jiang
                </i></font>
                <br>
                IEEE International Geoscience and Remote Sensing Symposium IGARSS, 2021
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="../../source/pdf/article_mei_igarss_2021.pdf" target="_blank">PDF</a>
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('MeiIGARSS2021Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('MeiIGARSS2021Bib')">BibTeX</a> &nbsp;
            </p>
            <p id="MeiIGARSS2021Abs" class="abstract" style="display: none;">
                Single image super-resolution (SISR) is an important procedure to improve many remote sensing applications. Global features play an important role in pixel generation of SISR. In this paper, we proposed a self-attention fusion module named as SAF module which combines spatial attention and channel attention in parallel to handle this problem. Our self-attention fusion module can be flexibly added to many popular deep-learning-based SISR models to further improve their representation ability and learn global features. Experiments on UC Merced dataset indicate that SAF module can improve the performance of classic SISR models and achieve state-of-the-art super-resolution results.
            </p>
            <pre xml:space="preserve" id="MeiIGARSS2021Bib" class="bibtex" style="display: none;">
@INPROCEEDINGS{9553766,
  author={Mei, Han and Zhang, Haopeng and Jiang, Zhiguo},
  booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS},
  title={Self-Attention Fusion Module for Single Remote Sensing Image Super-Resolution},
  year={2021},
  volume={},
  number={},
  pages={2883-2886},
  doi={10.1109/IGARSS47720.2021.9553766}}
              </pre>
                  <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('MeiIGARSS2021Abs');
                hideblock('MeiIGARSS2021Bib');
              </script>
              </td>
          </tr> <!-- Paper End Here -->

                </tbody></table>
              </div>
              <div class="get-more" align="right"><a href="publications.html"> 更多 </a></div>
            </div>
          </introduce>
        </div>
        <!-- Slid Page -->
        <div class="col-md-4 sidebar-gutter">
          <aside>
          <!-- sidebar-widget -->
          <div class="sidebar-widget">
            <div class="widget-container widget-main">
              <img src="../../images/photo/JiangZG.jpg" alt="JiangZG's photo">
              <h4>姜志国</h4>
              <div class="author-title">教授</div>
              <p>
                <b>地址:</b> 北京市昌平区沙河高教园南三街9号<br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp<br> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp邮编102206<br>
                <b>邮箱:</b> <a href="mailto:jiangzg@buaa.edu.cn">jiangzg@buaa.edu.cn</a><br>
<!--
                <b>电话:</b> TBA<br>
                <b>传真:</b> TBA<br>
-->
                <b>办公:</b> 主楼D721<br>
              </p>
            </div>
          </div>
          <!-- sidebar-widget -->
          <div class="sidebar-widget">
            <h3 class="sidebar-title">团队成员</h3>
            <div class="widget-container">
              <article class="widget-block">
                <div class="block-image"> <img src="../../images/photo/ZhangHP.jpg" alt="ZhangHP's photo"> </div>
                <div class="block-body">
                  <h2><a href="http://teacher.buaa.edu.cn/zhanghaopeng/" target="_blank">张浩鹏 <i class="fa fa-external-link"></i></a></h2>
                  <div class="icon-meta">
                    <span><i class="fa fa-graduation-cap"></i>副教授</span> <span><i class="fa fa-clock-o"></i> </span>
                    <br><span><i class="fa fa-envelope-o"></i> <a href="mailto:zhanghaopeng@buaa.edu.cn">zhanghaopeng@buaa.edu.cn</a></span>
                  </div>
                </div>
              </article>
              <article class="widget-block">
                <div class="block-image"> <img src="../../images/photo/XieFY.jpg" alt="ZhangYS's photo"> </div>
                <div class="block-body">
                  <h2><a href="http://www.sa.buaa.edu.cn/info/1014/4773.htm" target="_blank">谢凤英 <i class="fa fa-external-link"></i></a></h2>
                  <div class="icon-meta">
                    <span><i class="fa fa-graduation-cap"></i>副教授</span> <span><i class="fa fa-clock-o"></i> </span>
                    <br><span><i class="fa fa-envelope-o"></i> <a href="mailto:xfy_73@buaa.edu.cn">xfy_73@buaa.edu.cn</a></span>
                  </div>
                </div>
              </article>
              <article class="widget-block">
                <div class="block-image"> <img src="../../images/photo/ZhaoDP.jpg" alt="ZhangYS's photo"> </div>
                <div class="block-body">
                  <h2><a href="http://www.sa.buaa.edu.cn/info/1014/4780.htm" target="_blank">赵丹培 <i class="fa fa-external-link"></i></a></h2>
                  <div class="icon-meta">
                    <span><i class="fa fa-graduation-cap"></i>副教授</span> <span><i class="fa fa-clock-o"></i> </span>
                    <br><span><i class="fa fa-envelope-o"></i> <a href="mailto:zhaodanpei@buaa.edu.cn">zhaodanpei@buaa.edu.cn</a></span>
                  </div>
                </div>
              </article>
              <article class="widget-block">
                <div class="block-image"> <img src="../../images/photo/ZhengYS.jpg" alt="ZhangYS's photo"> </div>
                <div class="block-body">
                  <h2><a href="https://zhengyushan.github.io" target="_blank">郑钰山 <i class="fa fa-external-link"></i></a></h2>
                  <div class="icon-meta">
                    <span><i class="fa fa-graduation-cap"></i>副教授</span> <span><i class="fa fa-clock-o"></i> </span>
                    <br><span><i class="fa fa-envelope-o"></i> <a href="mailto:yszheng@buaa.edu.cn">yszheng@buaa.edu.cn</a></span>
                  </div>
                </div>
              </article>
            </div>
          </div>
          <!-- sidebar-widget -->
          <div class="sidebar-widget">
            <h3 class="sidebar-title">相关链接</h3>
            <div class="widget-container">
              <ul style="list-style: none; padding-left: 10px;">
                <!-- <li><i class="fa fa-external-link"></i> <a href="https://remex-lab.github.io/" target="_blank">REMEX </a></li> -->
                <li><i class="fa fa-external-link"></i> <a href="http://teacher.buaa.edu.cn/zhanghaopeng/" target="_blank">张浩鹏个人主页</a></li>
                <li><i class="fa fa-external-link"></i> <a href="http://xfy.buaa.edu.cn" target="_blank">谢凤英个人主页</a></li>
                <li><i class="fa fa-external-link"></i> <a href="http://www.sa.buaa.edu.cn/info/1014/4780.htm" target="_blank">赵丹培个人主页</a></li>
                <li><i class="fa fa-external-link"></i> <a href="https://zhengyushan.github.io" target="_blank">郑钰山个人主页</a></li> 
              </ul>
            </div>
          </div>
          </aside>
        </div>
      </div>
    </section>
    </div><!-- /.container -->

    <footer class="footer">
      <div class="footer-bottom">  
        <i class="fa fa-copyright"></i> Copyright 2018. All rights reserved.<br>
        <!-- <i class="fa fa-anchor"></i> <a href="index_x.html"><b>X！</b><i class="fa fa-sign-in"></i></a> -->
      </div>
      
    </footer>


    <!-- Bootstrap core JavaScript
      ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../../scripts/jquery.min.js"></script>
    <script src="../../scripts/bootstrap.min.js"></script>
    <script src="../../scripts/jquery.bxslider.js"></script>
    <script src="../../scripts/mooz.scripts.min.js"></script>
    <script src="../../scripts/togglehide.js"></script>
  </body>
</html>
