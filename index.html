<!DOCTYPE html>
<html lang="zh-CN">

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="Home page of REMEX">
    <meta name="author" content="WeiQM">
    <link rel="icon" href="images/logo/RMX_16.ico">
    <title>REMEX - Remote sensing + Medical imaging + X-features</title>
    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="style/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <!-- Custom styles for this template -->
    <link href="style/jquery.bxslider.css" rel="stylesheet">
    <link href="style/style.css" rel="stylesheet">
  </head>

  <body>
    <!-- Navigation -->
    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          </button>
        </div>
        <div id="navbar" class="collapse navbar-collapse">  
          <ul class="nav navbar-nav">
            <li class="active"><a href="index.html">Home</a></li>
            <li><a href="people.html">People</a></li>
            <li><a href="research.html">Research</a></li>
            <li><a href="publications.html">Publications</a></li>
            <li><a href="downloads.html">Downloads</a></li>
            <li><a href="contact.html">Contact Us</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <li class="active"><a href="index.html">English</a></li>
            <li><a href="html/cn/index.html">中文</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <li><a href="index.html"><img src="images/logo/logo_w.png" alt="Logo" width="80px"/></a></li>
          </ul>
        </div>
      </div>
    </nav>
    <div class="container">
    <header>
      <!--
      <a href="index.html"><img src="images/logo.png"  width="256px"></a>
      -->
    </header>
    <!--
    <section class="main-slider">
      <ul class="bxslider">
        <li><div class="slider-item"><img src="images/logo/logo_c.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_m.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_y.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_k.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_r.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_g.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_b.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
      </ul>
    </section>
    -->
    <section>
      <div class="row">
        <!-- Main Page -->
        <div class="col-md-8">
          <introduce class="content-block">
            <div class="block-body">
              <img src="images/logo.png" alt="Logo" width="512px">
              <p><br>
                <b>REMEX</b> (<b>Re</b>mote sensing and <b>Me</b>dical imaging with <b>X</b>-features) is a research group directed by Prof. Zhiguo Jiang. The main research interest includes image processing, computer vision, pattern recognition,  deep learning, and their applications on remote sensing, medical imaging.
              </p>
              
              <div class="block-image">
                <img src="images/photo/Team.jpg" alt="Team photo">
              </div>
              
              <hr/>
              <h3 align="left">Recently Published</h3><br />
              <div class="block-text">
            <table><tbody>
              <tr> <!-- An Paper -->
                <p>
                    <b>Encoding Histopathology Whole Slide Images with Location-aware Graphs for Diagnostically Relevant Regions Retrieval</b> <a href="https://doi.org/10.1016/j.media.2021.102308" target="_blank"><i class="fa fa-external-link"></i></a>
                    <br>
                    <font size="3pt" face="Georgia"><i>
                        <a href="https://zhengyushan.github.io" target="_blank">Yushan Zheng</a>, Zhiguo Jiang*, Jun Shi, Fengying Xie, <a href="https://haopzhang.github.io" target="_blank">Haopeng Zhang</a>, Wei Luo, Dingyi Hu, Shujiao Sun, Zhongmin Jiang, and Chenghai Xue
                    </i></font>
                    <br>
                    Medical Image Analysis, 2022
                    <br>
                    <i class="fa fa-file-pdf-o"></i> <a href="source/pdf/article_zheng_mia_2021.pdf" target="_blank">PDF</a>
                    <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('ZhengMIA2021Abs')">Abstract</a> &nbsp;
                    <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('ZhengMIA2021Bib')">BibTeX</a> &nbsp;
                    <i class="fa fa-github"></i> <a href="https://github.com/Zhengyushan/lagenet" target="_blank">Code</a>
                </p>
                <p id="ZhengMIA2021Abs" class="abstract" style="display: none;">
                    Content-based histopathological image retrieval (CBHIR) has become popular in recent years in histopathological image analysis. CBHIR systems provide auxiliary diagnosis information for pathologists by searching for and returning regions that are contently similar to the region of interest (ROI) from a pre-established database. It is challenging and yet significant in clinical applications to retrieve diagnostically relevant regions from a database consisting of histopathological whole slide images (WSIs). In this paper, we propose a novel framework for regions retrieval from WSI database based on location-aware graphs and deep hash techniques. Compared to the present CBHIR framework, both structural information and global location information of ROIs in the WSI are preserved by graph convolution and self-attention operations, which makes the retrieval framework more sensitive to regions that are similar in tissue distribution. Moreover, benefited from the graph structure, the proposed framework has good scalability for both the size and shape variation of ROIs. It allows the pathologist to define query regions using free curves according to the appearance of tissue. Thirdly, the retrieval is achieved based on the hash technique, which ensures the framework is efficient and adequate for practical large-scale WSI database. The proposed method was evaluated on an in-house endometrium dataset with 2650 WSIs and the public ACDC-LungHP dataset. The experimental results have demonstrated that the proposed method achieved a mean average precision above 0.667 on the  endometrium dataset and above 0.869 on the ACDC-LungHP dataset in the task of irregular region retrieval, which are superior to the state-of-the-art methods. The average retrieval time from a database containing 1855 WSIs is 0.752 ms.
                </p>
                <pre xml:space="preserve" id="ZhengMIA2021Bib" class="bibtex" style="display: none;">
  @Article{zheng2022encoding,
    author  = {Zheng, Yushan and Jiang, Zhiguo and Shi, Jun and Xie, Fengying and Zhang, Haopeng and
                Luo, Wei and Hu, Dingyi and Sun, Shujiao and Jiang, Zhongmin and Xue, Chenghai},
    title   = {Encoding histopathology whole slide images with location-aware graphs for diagnostically relevant regions retrieval},
    journal = {Medical Image Analysis},
    year    = {2022},
    volumn  = {76},
    pages   = {102308},
    doi     = {https://doi.org/10.1016/j.media.2021.102308},
  }
                </pre>
                    <script language="javascript" type="text/javascript" xml:space="preserve">
                  hideblock('ZhengMIA2021Abs');
                  hideblock('ZhengMIA2021Bib');
                </script>
                </td>
            </tr> <!-- Paper End Here -->   
            <tr> <!-- An Paper -->
              <p>
                  <b>Weakly Supervised Histopathological Image Representation Learning based on Contrastive Dynamic Clustering</b> <!--a href="https://doi.org/10.1016/j.media.2021.102308" target="_blank"><i class="fa fa-external-link"></i></a-->
                  <br>
                  <font size="3pt" face="Georgia"><i>
                      Jun Li, Zhiguo Jiang, <a href="https://zhengyushan.github.io" target="_blank">Yushan Zheng*</a>, <a href="https://haopzhang.github.io" target="_blank">Haopeng Zhang</a>, Jun Shi, Dingyi Hu,  Wei Luo, Zhongmin Jiang, and Chenghai Xue
                  </i></font>
                  <br>
                  SPIE Medical Imaging, 2022
                  <br>
                  <i class="fa fa-file-pdf-o"></i> <a href="source/pdf/article_li_spiemi_2022.pdf" target="_blank">PDF</a>
                  <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('LiSPIEMI2022Abs')">Abstract</a> &nbsp;
                  <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('LiSPIEMI2022Bib')">BibTeX</a> &nbsp;
                  <i class="fa fa-github"></i> <a href="https://github.com/junl21/cdc" target="_blank">Code</a>
              </p>
              <p id="LiSPIEMI2022Abs" class="abstract" style="display: none;">
                  Feature representations of histopathology whole slide images (WSIs) are crucial to the downstream applications
                  for computer-aided cancer diagnosis, including whole slide image classification, region of interest detection, hash
                  retrieval, prognosis analysis, and other high-level inference tasks. State-of-the-art methods for whole slide image
                  feature extraction generally rely on supervised learning algorithms based on fine-grained manual annotations,
                  unsupervised learning algorithms without annotation, or directly use pre-trained features. At present, there is
                  a lack of research on weakly supervised feature learning methods that only utilize WSI-level labeling. In this
                  paper, we propose a weakly supervised framework that learns the feature representations of various lesion areas
                  from histopathology whole slide images. The proposed framework consists of a contrastive learning network as
                  the backbone and a designed contrastive dynamic clustering (CDC) module to embedding the lesion information
                  into the feature representations. The proposed method was evaluated on a large scale endometrial whole slide
                  image dataset. The experimental results have demonstrated that our method can learn discriminative feature
                  representations for histopathology image classification and the quantitative performance of our method is close
                  to the fully-supervision learning methods
              </p>
              <pre xml:space="preserve" id="LiSPIEMI2022Bib" class="bibtex" style="display: none;">
@inproceedings{li2021weakly,
  author    = {Jun Li, Zhiguo Jiang, Yushan Zheng, Haopeng Zhang, Jun Shi, Dingyi Hu,
               Wei Luo, Zhongmin Jiang, and Chenghai Xue},
  title     = {Weakly Supervised Histopathological Image Representation Learning based on Contrastive Dynamic Clustering},
  booktitle = {SPEI Medical Imaging 2022},
  year      = {2022},
}
              </pre>
                  <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('LiSPIEMI2022Abs');
                hideblock('LiSPIEMI2022Bib');
              </script>
              </td>
          </tr> <!-- Paper End Here -->

          <tr> <!-- An Paper -->
            <p>
                <b>Hyperspectral Image Classification using Feature Fusion Hypergraph Convolution Neural Network</b> <a href="https://doi.org/10.1109/TGRS.2021.3123423" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                    Zhongtian Ma, Zhiguo Jiang, <a href="https://haopzhang.github.io" target="_blank">Haopeng Zhang</a>
                </i></font>
                <br>
                IEEE Transactions on Geoscience and Remote Sensing, 2021
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="source/pdf/article_ma_tgrs_2021.pdf" target="_blank">PDF</a>
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('MaTGRS2021Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('MaTGRS2021Bib')">BibTeX</a> &nbsp;
            </p>
            <p id="MaTGRS2021Abs" class="abstract" style="display: none;">
                Convolutional neural networks (CNN) and graph representation learning are two common methods for hyperspectral image (HSI) classification. Recently, graph convolutional neural networks (GCN), a combination of CNN and graph representation learning, have shown great potential in HSI classification problem. However, the existing GCN-based methods have many problems, such as over dependence on the adjacency matrix, usage of a single modal feature, and lower accuracy than the mature CNN method. In this paper, we propose a feature fusion hypergraph convolutional neural network (F2HNN) for HSI classification. F2HNN first generates hyperedges from features of different modalities to construct a hypergraph representing multi-modal features in HSI. Then, the HSI and the extracted hypergraph are input into the hypergraph convolutional neural network for learning. In addition, we proposes three feature fusion strategies. The first strategy is the most basic spatial and spectral feature fusion. The second strategy fuses the spectral features extracted by a pre-trained multilayer perceptron (MLP) with the spatial features to reduce the redundant information of the original spectral features. The third strategy uses the fusion of CNN features, spectral features and spatial features to explore the capabilities of F2HNN. Sufficient experiments on four datasets have proved the effectiveness of F2HNN.
            </p>
            <pre xml:space="preserve" id="MaTGRS2021Bib" class="bibtex" style="display: none;">
@ARTICLE{9590574,
author={Ma, Zhongtian and Jiang, Zhiguo and Zhang, Haopeng},
journal={IEEE Transactions on Geoscience and Remote Sensing},
title={Hyperspectral Image Classification using Feature Fusion Hypergraph Convolution Neural Network},
year={2021},
volume={},
number={},
pages={1-1},
doi={10.1109/TGRS.2021.3123423}
}

            </pre>
                <script language="javascript" type="text/javascript" xml:space="preserve">
              hideblock('MaTGRS2021Abs');
              hideblock('MaTGRS2021Bib');
            </script>
            </td>
        </tr> <!-- Paper End Here -->

        <tr> <!-- An Paper -->
          <p>
              <b>Self-Attention Fusion Module for Single Remote Sensing Image Super-Resolution</b> <a href="https://doi.org/10.1109/IGARSS47720.2021.9553766" target="_blank"><i class="fa fa-external-link"></i></a>
              <br>
              <font size="3pt" face="Georgia"><i>
                  Han Mei, <a href="https://haopzhang.github.io" target="_blank">Haopeng Zhang</a>, Zhiguo Jiang
              </i></font>
              <br>
              IEEE International Geoscience and Remote Sensing Symposium IGARSS, 2021
              <br>
              <i class="fa fa-file-pdf-o"></i> <a href="source/pdf/article_mei_igarss_2021.pdf" target="_blank">PDF</a>
              <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('MeiIGARSS2021Abs')">Abstract</a> &nbsp;
              <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('MeiIGARSS2021Bib')">BibTeX</a> &nbsp;
          </p>
          <p id="MeiIGARSS2021Abs" class="abstract" style="display: none;">
              Single image super-resolution (SISR) is an important procedure to improve many remote sensing applications. Global features play an important role in pixel generation of SISR. In this paper, we proposed a self-attention fusion module named as SAF module which combines spatial attention and channel attention in parallel to handle this problem. Our self-attention fusion module can be flexibly added to many popular deep-learning-based SISR models to further improve their representation ability and learn global features. Experiments on UC Merced dataset indicate that SAF module can improve the performance of classic SISR models and achieve state-of-the-art super-resolution results.
          </p>
          <pre xml:space="preserve" id="MeiIGARSS2021Bib" class="bibtex" style="display: none;">
@INPROCEEDINGS{9553766,
author={Mei, Han and Zhang, Haopeng and Jiang, Zhiguo},
booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS},
title={Self-Attention Fusion Module for Single Remote Sensing Image Super-Resolution},
year={2021},
volume={},
number={},
pages={2883-2886},
doi={10.1109/IGARSS47720.2021.9553766}}
            </pre>
                <script language="javascript" type="text/javascript" xml:space="preserve">
              hideblock('MeiIGARSS2021Abs');
              hideblock('MeiIGARSS2021Bib');
            </script>
            </td>
        </tr> <!-- Paper End Here -->
                </tbody></table>
              </div>
              <div class="get-more" align="right"><a href="publications.html"> More </a></div>
            </div>
          </introduce>
        </div>
        <!-- Slid Page -->
        <div class="col-md-4 sidebar-gutter">
          <aside>
          <!-- sidebar-widget -->
          <div class="sidebar-widget">
            <div class="widget-container widget-main">
              <img src="images/photo/JiangZG.jpg" alt="JiangZG's photo">
              <h4>Zhiguo Jiang</h4>
              <div class="author-title">Professor</div>
              <p>
                <b>Address:</b> 9 South-3rd Street, Shahe University Park, Changping District, Beijing, 102206, China<br>
                <b>E-mail:</b> <a href="mailto:jiangzg@buaa.edu.cn">jiangzg@buaa.edu.cn</a><br>
<!--
                <b>Tel:</b> TBA<br>
                <b>Fax:</b> TBA<br>
-->
                <b>Office:</b> D721, Main Building<br>

              </p>
            </div>
          </div>
          <!-- sidebar-widget -->
          <div class="sidebar-widget">
            <h3 class="sidebar-title">Researchers</h3>
            <div class="widget-container">
              <article class="widget-block">
                <div class="block-image"> <img src="images/photo/ZhangHP.jpg" alt="ZhangHP's photo"> </div>
                <div class="block-body">
                  <h2><a href="https://haopzhang.github.io/" target="_blank">Haopeng Zhang <i class="fa fa-external-link"></i></a></h2>
                  <div class="icon-meta">
                    <span><i class="fa fa-graduation-cap"></i>Associate Professor</span> <span><i class="fa fa-clock-o"></i> 2014.07 ~ Now</span>
                    <br><span><i class="fa fa-envelope-o"></i> <a href="mailto:zhanghaopeng@buaa.edu.cn">zhanghaopeng@buaa.edu.cn</a></span>
                  </div>
                </div>
              </article>
              <article class="widget-block">
                  <div class="block-image"> <img src="images/photo/ZhengYS2.jpg" alt="ZhengYS's photo"> </div>
                  <div class="block-body">
                    <h2><a href="https://zhengyushan.github.io" target="_blank">Yushan Zheng <i class="fa fa-external-link"></i></a></h2>
                    <div class="icon-meta">
                      <span><i class="fa fa-graduation-cap"></i>Tenure-track Associate Professor</span> <span><i class="fa fa-clock-o"></i> 2019.01 ~ Now</span>
                      <br><span><i class="fa fa-envelope-o"></i> <a href="mailto:yszheng@buaa.edu.cn">yszheng@buaa.edu.cn</a></span>
                    </div>
                  </div>
                </article>
            </div>
          </div>
          <!-- sidebar-widget -->
          <div class="sidebar-widget">
            <h3 class="sidebar-title">Contact Us</h3>
            <div class="widget-container">
              <p>
                <b>Address:</b> D208, Main Building, 9 South-3rd Street, Shahe University Park, Changping District, Beijing, 102206, China<br>
<!--
                <b>Tel:</b> TBA<br>
                <b>Fax:</b> TBA<br>
-->
              </p>
            </div>
          </div>
          <!-- sidebar-widget -->
          <div class="sidebar-widget">
            <h3 class="sidebar-title">Related Links</h3>
            <div class="widget-container">
              <ul style="list-style: none; padding-left: 10px;">
                <li><i class="fa fa-external-link"></i> <a href="https://remex-lab.github.io/" target="_blank">REMEX (on GitHub Server)</a></li>
                <li><i class="fa fa-external-link"></i> <a href="http://xfy.buaa.edu.cn" target="_blank">Xie's Lab</a></li>
                <li><i class="fa fa-external-link"></i> <a href="https://haopzhang.github.io/" target="_blank">Zhang's home page</a></li>
                <li><i class="fa fa-external-link"></i> <a href="https://zhengyushan.github.io" target="_blank">Zheng's home page</a></li>
              </ul>
            </div>
          </div>
          </aside>
        </div>
      </div>
    </section>
    </div><!-- /.container -->

    <footer class="footer">
      <div class="footer-bottom">  
        <i class="fa fa-copyright"></i> ````````````````1
          Copyright 2018. All rights reserved.<br>
        <!-- <i class="fa fa-anchor"></i> <a href="index_x.html"><b>X！</b><i class="fa fa-sign-in"></i></a> -->
      </div>
      
    </footer>


    <!-- Bootstrap core JavaScript
      ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="scripts/jquery.min.js"></script>
    <script src="scripts/bootstrap.min.js"></script>
    <script src="scripts/jquery.bxslider.js"></script>
    <script src="scripts/mooz.scripts.min.js"></script>
    <script src="scripts/togglehide.js"></script>
  </body>
</html>
