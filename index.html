<!DOCTYPE html>
<html lang="zh-CN">

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="Home page of REMEX">
    <meta name="author" content="WeiQM">
    <link rel="icon" href="images/logo/RMX_16.ico">
    <title>REMEX - Remote sensing + Medical imaging + X-features</title>
    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="style/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <!-- Custom styles for this template -->
    <link href="style/jquery.bxslider.css" rel="stylesheet">
    <link href="style/style.css" rel="stylesheet">
  </head>

  <body>
    <!-- Navigation -->
    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          </button>
        </div>
        <div id="navbar" class="collapse navbar-collapse">  
          <ul class="nav navbar-nav">
            <li class="active"><a href="index.html">Home</a></li>
            <li><a href="people.html">People</a></li>
            <li><a href="research.html">Research</a></li>
            <li><a href="publications.html">Publications</a></li>
            <li><a href="downloads.html">Downloads</a></li>
            <li><a href="contact.html">Contact Us</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <li class="active"><a href="index.html">English</a></li>
            <li><a href="html/cn/index.html">中文</a></li>
          </ul>
          <ul class="nav navbar-nav navbar-right">
            <li><a href="index.html"><img src="images/logo/logo_w.png" alt="Logo" width="80px"/></a></li>
          </ul>
        </div>
      </div>
    </nav>
    <div class="container">
    <header>
      <!--
      <a href="index.html"><img src="images/logo.png"  width="256px"></a>
      -->
    </header>
    <!--
    <section class="main-slider">
      <ul class="bxslider">
        <li><div class="slider-item"><img src="images/logo/logo_c.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_m.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_y.png" title="Logo" /><h2><a href="" title="Loge">New published !</a></h2></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_k.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_r.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_g.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
        <li><div class="slider-item"><img src="images/logo/logo_b.png" title="Logo" /><h3><a href="" title="Loge">New published !</a></h3></div></li>
      </ul>
    </section>
    -->
    <section>
      <div class="row">
        <!-- Main Page -->
        <div class="col-md-8">
          <introduce class="content-block">
            <div class="block-body">
              <img src="images/logo.png" alt="Logo" width="512px">
              <p><br>
                <b>REMEX</b> (<b>Re</b>mote sensing and <b>Me</b>dical imaging with <b>X</b>-features) is a research group directed by Prof. Zhiguo Jiang. This group is affiliated by the Image Processing Center, School of Astronautics, Beihang University, China. The main research interests include remote sensing image processing and analysis, medical imaging and analysis, space object image processing, computer vision, pattern recognition, and deep learning, etc.
              </p>
              
              <div class="block-image">
                <img src="images/photo/Team.jpg" alt="Team photo">
              </div>
              
              <hr/>
              <h3 align="left">Recently Published</h3><br />
              <div class="block-text">
              <table><tbody>
                <tr><td valign="top"><!-- An Paper -->
                    <p>
                      <strong style="color:red">[New]</strong>
                      <b>Stain Standardization Capsule: A pre-processing module for histopathological image analysis</b> <a href="https://openreview.net/forum?id=B1xPG55qZS" target="_blank"><i class="fa fa-external-link"></i></a>
                  <br>
                  <font size="3pt" face="Georgia"><i>
                      Yushan Zheng, Zhiguo Jiang, Haopeng Zhang, Jun Shi, and Fengying Xie
                  </i></font>
                  <br>
                    MICCAI 2019 Computational Pathology Workshop (COMPAY19) 
                  <br>
                  <i class="fa fa-file-pdf-o"></i> <a href="https://openreview.net/pdf?id=B1xPG55qZS" target="_blank">PDF</a> &nbsp;
                  <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhengMICCAI2019Abs')">Abstract</a> &nbsp;
                  <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhengMICCAI2019Bib')">BibTeX</a> &nbsp;
                </p>
                <p id="zhengMICCAI2019Abs" class="abstract" style="display: none;">
                  Color consistency is crucial to developing robust deep learning methods for histopathological image analysis. With the increasing use of digital histopathological images, the deep learning methods are likely developed based on the data from multiple medical centers. This requirement makes it a challenge task to normalize the color variance of histopathological images from different medical centers. In this paper, we proposed a novel color standardization module named stain standardization capsule (SSC) based on the paradigm of capsules network and the corresponding dynamic routing algorithm. The proposed module can learn and generate uniform stain separation outputs for histopathological images in various color appearance without the reference to manually selected template images. The SSC module is light and can be trained end-to-end with the application-driven CNN model. The proposed method was validated on two public datasets and compared with the state-of-the-art methods. The experimental results have demonstrated that the SSC module is effective in color normalization for histopathological images and achieves the best performance in the compared methods.</p>
                <pre xml:space="preserve" id="zhengMICCAI2019Bib" class="bibtex" style="display: none;">
  @article{zheng2019stain,
    title={Stain Standardization Capsule: A pre-processing module for histopathological image analysis},
    author={Zheng, Yushan and Jiang, Zhiguo and Zhang, Haopeng and Shi, Jun and Xie, Fengying},
    year={2019}
  }
                </pre>
                <script language="javascript" type="text/javascript" xml:space="preserve">
                  hideblock('zhengMICCAI2019Abs');
                  hideblock('zhengMICCAI2019Bib');
                    </script>
                  </td>
                </tr> <!-- Paper End Here -->
                <tr><td valign="top"><!-- An Paper -->
                  <p>
                    <strong style="color:red">[New]</strong>
                    <b>Graph Convolutional Networks for Cervical Cell Classification</b> <a href="https://openreview.net/forum?id=S1gX_tlc-S" target="_blank"><i class="fa fa-external-link"></i></a>
                  <br>
                  <font size="3pt" face="Georgia"><i>
                    Jun Shi, Ruoyu Wang, Yushan Zheng, Zhiguo Jiang, and Lanlan Yu
                  </i></font>
                  <br>
                    MICCAI 2019 Computational Pathology Workshop (COMPAY19)
                  <br>
                  <i class="fa fa-file-pdf-o"></i> <a href="https://openreview.net/pdf?id=S1gX_tlc-S" target="_blank">PDF</a> &nbsp;
                  <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('shiMICCAI2019Abs')">Abstract</a> &nbsp;
                  <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('shiMICCAI2019Bib')">BibTeX</a> &nbsp;
                </p>
                <p id="shiMICCAI2019Abs" class="abstract" style="display: none;">
                  Cervical cell classification is of important clinical significance in the screening of cervical cancer at early stages. In this paper, we present a novel cervical cell clas-sification method based on Graph Convolutional Network (GCN). In contrast with Convolutional Neural Networks (CNN) which can classify cervical cells through learned deep features, the proposed method uses GCN to explore the im-age-level potential relationship for improving the classification performance. Spe-cifically, each cervical cell image is represented by a pre-trained CNN. k-means clustering is performed on these CNN features and then the graph structure is constructed where each node is characterized by one cluster centroid. Conse-quently, the image-level relationship can be captured in terms of intrinsic cluster-ing structure. GCN is applied to propagate the underlying correlation of nodes and the relation-aware representation of GCN is incorporated to enrich the image-level CNN features. Experiments on the cervical cell image datasets demonstrate the excellent superiority of our method.</p>
                <pre xml:space="preserve" id="shiMICCAI2019Bib" class="bibtex" style="display: none;">
  @article{shi2019graph,
    title={Graph Convolutional Networks for Cervical Cell Classification},
    author={Shi, Jun and Wang, Ruoyu and Zheng, Yushan and Jiang, Zhiguo and Yu, Lanlan},
    year={2019}
  }             
                </pre>
                <script language="javascript" type="text/javascript" xml:space="preserve">
                  hideblock('shiMICCAI2019Abs');
                  hideblock('shiMICCAI2019Bib');
                  </script>
                </td></tr> <!-- Paper End Here -->
                <tr><td valign="top"><!-- An Paper -->
                  <p>
                    <strong style="color:red">[New]</strong>
                    <b>Real-time 6D pose estimation from a single RGB image</b> <a href="https://www.sciencedirect.com/science/article/pii/S0262885619300964" target="_blank"><i class="fa fa-external-link"></i></a>
                  <br>
                  <font size="3pt" face="Georgia"><i>
                      Xin Zhang, Zhiguo Jiang, and Haopeng Zhang
                  </i></font>
                  <br>
                    Image and Vision Computing, 2019
                  <br>
                  <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhangIVC2019Abs')">Abstract</a> &nbsp;
                  <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhangIVC2019Bib')">BibTeX</a> &nbsp;
                </p>
                <p id="zhangIVC2019Abs" class="abstract" style="display: none;">
                    We propose an end-to-end deep learning architecture for simultaneously detecting objects and recovering 6D poses in an RGB image. Concretely, we extend the 2D detection pipeline with a pose estimation module to indirectly regress the image coordinates of the object's 3D vertices based on 2D detection results. Then the object's 6D pose can be estimated using a Perspective-n-Point algorithm without any post-refinements. Moreover, we elaborately design a backbone structure to maintain spatial resolution of low level features for pose estimation task. Compared with state-of-the-art RGB based pose estimation methods, our approach achieves competitive or superior performance on two benchmark datasets at an inference speed of 25 fps on a GTX 1080Ti GPU, which is capable of real-time processing.</p>
                <pre xml:space="preserve" id="zhangIVC2019Bib" class="bibtex" style="display: none;">
  @article{zhang2019real,
    title={Real-time 6D pose estimation from a single RGB image},
    author={Zhang, Xin and Jiang, Zhiguo and Zhang, Haopeng},
    journal={Image and Vision Computing},
    volume={89},
    pages={1--11},
    year={2019},
    publisher={Elsevier}
  }
                </pre>
                <script language="javascript" type="text/javascript" xml:space="preserve">
                  hideblock('zhangIVC2019Abs');
                  hideblock('zhangIVC2019Bib');
                    </script>
                  </td></tr> <!-- Paper End Here -->
                  <tr><td> <!-- An Paper -->
                    <p>
                      <strong style="color:red">[New]</strong>
                      <b>Adaptive Color Deconvolution For Histological WSI Normalization</b> <a href="https://www.sciencedirect.com/science/article/pii/S0169260718312161" target="_blank"><i class="fa fa-external-link"></i></a>
                <br>
                <font size="3pt" face="Georgia"><i>
                    Yushan Zheng, Zhiguo Jiang, Haopeng Zhang, Fengying Xie, Jun Shi, and Chenghai Xue
                </i></font>
                <br>
                  Computer Methods and Programs in Biomedicine, 2019
                <br>
                <i class="fa fa-file-pdf-o"></i> <a href="source/pdf/article_zheng_cmpb_2019.pdf" target="_blank">PDF</a> &nbsp;
                <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhengCMPB2019Abs')">Abstract</a> &nbsp;
                <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhengCMPB2019Bib')">BibTeX</a> &nbsp;
                <i class="fa fa-code"></i> <a href="https://github.com/Zhengyushan/adaptive_color_deconvolution" target="_blank">Code</a> &nbsp
              </p>
              <p id="zhengCMPB2019Abs" class="abstract" style="display: none;">
                <b>Background and Objective</b>
                Color consistency of histological images is significant for developing reliable computer-aided diagnosis (CAD) systems. However, the color appearance of digital histological images varies across different specimen preparations, staining, and scanning situations. This variability affects the diagnosis and decreases the accuracy of CAD approaches. It is important and challenging to develop effective color normalization methods for digital histological images.
                <b>Methods</b>
                We proposed a novel adaptive color deconvolution (ACD) algorithm for stain separation and color normalization of hematoxylin-eosin-stained whole slide images (WSIs). To avoid artifacts and reduce the failure rate of normalization, multiple prior knowledges of staining are considered and embedded in the ACD model. To improve the capacity of color normalization for various WSIs, an integrated optimization is designed to simultaneously estimate the parameters of the stain separation and color normalization. The solving of ACD model and application of the proposed method involves only pixel-wise operation, which makes it very efficient and applicable to WSIs.
                <b>Results</b>
                The proposed method was evaluated on four WSI-datasets including breast, lung and cervix cancers and was compared with 6 state-of-the-art methods. The proposed method achieved the most consistent performance in color normalization according to the quantitative metrics. Through a qualitative assessment for 500 WSIs, the failure rate of normalization was 0.4% and the structure and color artifacts were effectively avoided. Applied to CAD methods, the area under receiver operating characteristic curve for cancer image classification was improved from 0.842 to 0.914. The average time of solving the ACD model is 2.97 s.
                <b>Conclusions</b>
                The proposed ACD model has prone effective for color normalization of hematoxylin-eosin-stained WSIs in various color appearances. The model is robust and can be applied to WSIs containing different lesions. The proposed model can be efficiently solved and is effective to improve the performance of cancer image recognition, which is adequate for developing automatic CAD programs and systems based on WSIs.</p>
              <pre xml:space="preserve" id="zhengCMPB2019Bib" class="bibtex" style="display: none;">
@article{zhengCMPB2019,
  title   = {Adaptive color deconvolution for histological WSI normalization},
  author  = {Yushan Zheng and Zhiguo Jiang and Haopeng Zhang and Fengying Xie and Jun Shi and Chenghai Xue},
  journal = {Computer Methods and Programs in Biomedicine},
  volume  = {170},
  pages   = {107-120},
  doi     = {doi.org/10.1016/j.cmpb.2019.01.008},
  year    = {2019}
}
              </pre>
              <script language="javascript" type="text/javascript" xml:space="preserve">
                hideblock('zhengCMPB2019Abs');
                hideblock('zhengCMPB2019Bib');
                    </script>
                  </td></tr> <!-- Paper End Here -->
                  <tr> <!-- An Paper -->
                    <p>
                      <strong style="color:red">[New]</strong>
                      <b>A Comparable Study of CNN-Based Single Image Super-Resolution for Space-Based Imaging Sensors</b> <a href="https://www_mdpi.gg363.site/1424-8220/19/14/3234" target="_blank"><i class="fa fa-external-link"></i></a>
                  <br>
                  <font size="3pt" face="Georgia"><i>
                      Haopeng Zhang, Pengrui Wang, Cong Zhang, and Zhiguo Jiang
                  </i></font>
                  <br>
                   Sensors, 2019
                  <br>
                  <i class="fa fa-bookmark-o"></i> <a href="javascript:toggleblock('zhangsensors2019Abs')">Abstract</a> &nbsp;
                  <i class="fa fa-quote-left"></i> <a href="javascript:toggleblock('zhangsensors2019Bib')">BibTeX</a> &nbsp;
                </p>
                <p id="zhangsensors2019Abs" class="abstract" style="display: none;">
                    In the case of space-based space surveillance (SBSS), images of the target space objects captured by space-based imaging sensors usually suffer from low spatial resolution due to the extremely long distance between the target and the imaging sensor. Image super-resolution is an effective data processing operation to get informative high resolution images. In this paper, we comparably study four recent popular models for single image super-resolution based on convolutional neural networks (CNNs) with the purpose of space applications. We specially fine-tune the super-resolution models designed for natural images using simulated images of space objects, and test the performance of different CNN-based models in different conditions that are mainly considered for SBSS. Experimental results show the advantages and drawbacks of these models, which could be helpful for the choice of proper CNN-based super-resolution method to deal with image data of space objects.</p>
                <pre xml:space="preserve" id="zhangsensors2019Bib" class="bibtex" style="display: none;">
  @article{zhang2019comparable,
    title={A Comparable Study of CNN-Based Single Image Super-Resolution for Space-Based Imaging Sensors},
    author={Zhang, Haopeng and Wang, Pengrui and Zhang, Cong and Jiang, Zhiguo},
    journal={Sensors},
    volume={19},
    number={14},
    pages={3234},
    year={2019},
    publisher={Multidisciplinary Digital Publishing Institute}
  }              
                </pre>
                <script language="javascript" type="text/javascript" xml:space="preserve">
                  hideblock('zhangsensors2019Abs');
                  hideblock('zhangsensors2019Bib');
                    </script>
                  </td>
                </tr> <!-- Paper End Here -->
                </tbody></table>
              </div>
              <div class="get-more" align="right"><a href="publications.html"> More </a></div>
            </div>
          </introduce>
        </div>
        <!-- Slid Page -->
        <div class="col-md-4 sidebar-gutter">
          <aside>
          <!-- sidebar-widget -->
          <div class="sidebar-widget">
            <div class="widget-container widget-main">
              <img src="images/photo/JiangZG.jpg" alt="JiangZG's photo">
              <h4>Zhiguo Jiang</h4>
              <div class="author-title">Professor</div>
              <p>
                <b>Address:</b> No. 9 Nansan Street, Higher Education Park, Changping District, Beijing, P.R. China, 102206<br>
                <b>E-mail:</b> <a href="mailto:jiangzg@buaa.edu.cn">jiangzg@buaa.edu.cn</a><br>
                <b>Tel:</b> +86-010-8231-6173<br>
                <b>Fax:</b> +86-010-8233-8798<br>
                <b>Office:</b> National Laboratory of Aeronautical Science and Technology-D721<br>
                <b>Research Interests:</b><br> 
              </p>
            </div>
          </div>
          <!-- sidebar-widget -->
          <div class="sidebar-widget">
            <h3 class="sidebar-title">Researchers</h3>
            <div class="widget-container">
              <article class="widget-block">
                <div class="block-image"> <img src="images/photo/XieFY.jpg" alt="XieFY's photo"> </div>
                <div class="block-body">
                  <h2><a href="http://xfy.buaa.edu.cn" target="_blank">Fengying Xie <i class="fa fa-external-link"></i></a></h2>
                  <div class="icon-meta">
                    <span><i class="fa fa-graduation-cap"></i> Professor</span> <span><i class="fa fa-clock-o"></i> 2011.01 ~ Now</span>
                    <br><span><i class="fa fa-envelope-o"></i> <a href="mailto:xfy_73@buaa.edu.cn">xfy_73@buaa.edu.cn</a></span>
                  </div>
                </div>
              </article>
              <article class="widget-block">
                <div class="block-image"> <img src="images/photo/ZhaoDP.jpg" alt="ZhaoDP's photo"> </div>
                <div class="block-body">
                  <h2>Danpei Zhao</h2>
                  <div class="icon-meta">
                    <span><i class="fa fa-graduation-cap"></i>Associate Professor</span> <span><i class="fa fa-clock-o"></i> 2011.01 ~ Now</span>
                    <br><span><i class="fa fa-envelope-o"></i> <a href="mailto:zhaodanpei@buaa.edu.cn">zhaodanpei@buaa.edu.cn</a></span>
                  </div>
                </div>
              </article>
              <article class="widget-block">
                <div class="block-image"> <img src="images/photo/ZhangHP.jpg" alt="ZhangHP's photo"> </div>
                <div class="block-body">
                  <h2><a href="https://haopzhang.github.io/" target="_blank">Haopeng Zhang <i class="fa fa-external-link"></i></a></h2>
                  <div class="icon-meta">
                    <span><i class="fa fa-graduation-cap"></i>Assistant Professor</span> <span><i class="fa fa-clock-o"></i> 2011.01 ~ Now</span>
                    <br><span><i class="fa fa-envelope-o"></i> <a href="mailto:zhanghaopeng@buaa.edu.cn">zhanghaopeng@buaa.edu.cn</a></span>
                  </div>
                </div>
              </article>
            </div>
          </div>
          <!-- sidebar-widget -->
          <div class="sidebar-widget">
            <h3 class="sidebar-title">Contact Us</h3>
            <div class="widget-container">
              <p>
                <b>Address:</b> National Laboratory of Aeronautical Science and Technology D-7th floor, Beihang University, Shahe University Park, Changping, Beijing 102206, P.R. China<br>
                <b>Tel:</b> TBA<br>
                <b>Fax:</b> TBA<br>
              </p>
            </div>
          </div>
          <!-- sidebar-widget -->
          <div class="sidebar-widget">
            <h3 class="sidebar-title">Related Links</h3>
            <div class="widget-container">
              <ul style="list-style: none; padding-left: 10px;">
                <li><i class="fa fa-external-link"></i> <a href="https://remex-lab.github.io/" target="_blank">REMEX (on GitHub Server)</a></li>
                <li><i class="fa fa-external-link"></i> <a href="http://xfy.buaa.edu.cn" target="_blank">Xie's Lab</a></li>
                <li><i class="fa fa-external-link"></i> <a href="http://ev.buaa.edu.cn/" target="_blank">Beihang University</a></li>
                <li><i class="fa fa-external-link"></i> <a href="http://www.sa.buaa.edu.cn/xysy.htm" target="_blank">School of Astronautics</a></li>
              </ul>
            </div>
          </div>
          </aside>
        </div>
      </div>
    </section>
    </div><!-- /.container -->

    <footer class="footer">
      <div class="footer-bottom">  
        <i class="fa fa-copyright"></i> Copyright 2018. All rights reserved.<br>
        <i class="fa fa-anchor"></i> <a href="index_x.html"><b>X！</b><i class="fa fa-sign-in"></i></a>
      </div>
      
    </footer>


    <!-- Bootstrap core JavaScript
      ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="scripts/jquery.min.js"></script>
    <script src="scripts/bootstrap.min.js"></script>
    <script src="scripts/jquery.bxslider.js"></script>
    <script src="scripts/mooz.scripts.min.js"></script>
    <script src="scripts/togglehide.js"></script>
  </body>
</html>
